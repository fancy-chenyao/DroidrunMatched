"""
ç»éªŒè®°å¿†ç³»ç»Ÿ - æ ¸å¿ƒè®°å¿†ç®¡ç†æ¨¡å—
è´Ÿè´£ç»éªŒçš„å­˜å‚¨ã€æ£€ç´¢ã€åŒ¹é…å’Œé€‚é…
"""
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import json
import os
import re
import uuid
import logging
import time
from droidrun.agent.utils.logging_utils import LoggingUtils

logger = logging.getLogger("droidrun")

@dataclass
class TaskExperience:
    """ä»»åŠ¡ç»éªŒæ•°æ®ç»“æ„"""
    id: str
    goal: str
    type: Optional[str]
    success: bool
    timestamp: float
    page_sequence: List[Dict[str, Any]]
    action_sequence: List[Dict[str, Any]]
    ui_states: List[Dict[str, Any]]
    metadata: Dict[str, Any]
    similarity_score: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = asdict(self)
        
        # ä¿®å¤BUGï¼šç¡®ä¿å­—æ®µåæ­£ç¡®ï¼Œé˜²æ­¢å‡ºç°ç©ºå­—ç¬¦ä¸²é”®
        if '' in result:
            LoggingUtils.log_warning("TaskExperience", "Detected empty string key in experience dict, fixing...")
            # å°†ç©ºå­—ç¬¦ä¸²é”®çš„å€¼ç§»åŠ¨åˆ° action_sequence
            result['action_sequence'] = result.pop('')
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
        required_fields = ['id', 'goal', 'type', 'success', 'timestamp', 'page_sequence', 'action_sequence', 'ui_states', 'metadata']
        for field in required_fields:
            if field not in result:
                LoggingUtils.log_warning("TaskExperience", f"Missing required field: {field}")
        
        return result
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TaskExperience':
        """ä»å­—å…¸åˆ›å»ºå¯¹è±¡"""
        # å…¼å®¹æ—§æ ¼å¼çš„ç»éªŒæ–‡ä»¶
        if 'id' not in data:
            data['id'] = str(uuid.uuid4())
        if 'ui_states' not in data:
            data['ui_states'] = []
        if 'similarity_score' not in data:
            data['similarity_score'] = None
        return cls(**data)

class ExperienceMemory:
    """ç»éªŒè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, storage_dir: str = "experiences", llm=None):
        self.storage_dir = storage_dir
        self.llm = llm
        # self.experiences: List[TaskExperience] = []
        self.type_experience_cache: Dict[str, List[TaskExperience]] = {}
        self.supported_types = ["è¯·ä¼‘å‡", "å‘˜å·¥å·®æ—…"]
        self._ensure_storage_dirs()
        self._load_type_experiences()
        # LoggingUtils.log_info("ExperienceMemory", "ExperienceMemory initialized with {count} experiences", count=len(self.experiences))
    
    def _ensure_storage_dir(self):
        """ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨"""
        os.makedirs(self.storage_dir, exist_ok=True)

    def _ensure_storage_dirs(self):
        """ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨"""
        os.makedirs(self.storage_dir, exist_ok=True)

        for type_name in self.supported_types:
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆé¿å…æ–‡ä»¶å¤¹å‘½åéæ³•ï¼‰
            safe_type_name = re.sub(r'[<>:"/\\|?*]', '_', type_name)
            type_dir = os.path.join(self.storage_dir, safe_type_name)
            os.makedirs(type_dir, exist_ok=True)

    def _load_experiences(self):
        """ä»å­˜å‚¨ç›®å½•åŠ è½½æ‰€æœ‰ç»éªŒ"""
        self.experiences = []
        if not os.path.exists(self.storage_dir):
            return

        for filename in os.listdir(self.storage_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(self.storage_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        experience = TaskExperience.from_dict(data)
                        self.experiences.append(experience)
                except Exception as e:
                    LoggingUtils.log_warning("ExperienceMemory", "Failed to load experience from {filename}: {error}",
                                            filename=filename, error=e)

    def _load_type_experiences(self):
        """é¢„åŠ è½½æ‰€æœ‰ç±»å‹æ–‡ä»¶å¤¹ä¸‹çš„ç»éªŒï¼ŒæŒ‰ç±»å‹ç¼“å­˜åˆ° type_experience_cache"""
        # éå†æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ˆå³ task_type æ–‡ä»¶å¤¹ï¼‰
        if not os.path.exists(self.storage_dir):
            return

        for type_dir in os.listdir(self.storage_dir):
            type_dir_path = os.path.join(self.storage_dir, type_dir)
            if not os.path.isdir(type_dir_path):
                continue  # è·³è¿‡éæ–‡ä»¶å¤¹

            task_type = type_dir

            # åŠ è½½è¯¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ç»éªŒ
            experiences = []
            for filename in os.listdir(type_dir_path):
                if filename.endswith('.json'):
                    filepath = os.path.join(type_dir_path, filename)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            exp = TaskExperience.from_dict(data)
                            experiences.append(exp)
                    except Exception as e:
                        LoggingUtils.log_warning("ExperienceMemory", f"Failed to load {filename}: {e}")

            # ç¼“å­˜è¯¥ç±»å‹çš„ç»éªŒ
            self.type_experience_cache[task_type] = experiences
            LoggingUtils.log_info("ExperienceMemory", f"Preloaded {len(experiences)} experiences for type: {task_type}")

    def find_similar_experiences(self, goal: str, threshold: float = 0.8) -> List[TaskExperience]:
        """æŸ¥æ‰¾ç›¸ä¼¼ç»éªŒ - ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰åŒ¹é…"""
        if not self.llm:
            LoggingUtils.log_warning("ExperienceMemory", "No LLM provided for similarity matching")
            return []
        
        similar_experiences = []
        
        for experience in self.experiences:
            try:
                similarity = self._calculate_similarity(goal, experience.goal)
                print("experience goal:", experience.goal)
                print("similarity:", similarity)
                # è®°å½•æ¯æ¡ç»éªŒçš„ç›¸ä¼¼åº¦ä¸é˜ˆå€¼æ¯”è¾ƒ
                try:
                    LoggingUtils.log_debug("ExperienceMemory", "Similarity calculation: {similarity:.2f} threshold={threshold:.2f} goal={goal}", 
                                         similarity=similarity, threshold=threshold, goal=experience.goal)
                except Exception:
                    pass
                if similarity >= threshold:
                    experience.similarity_score = similarity
                    similar_experiences.append(experience)
                else:
                    try:
                        LoggingUtils.log_debug("ExperienceMemory", "Similarity below threshold: {similarity:.2f} < {threshold:.2f} goal={goal}", 
                                             similarity=similarity, threshold=threshold, goal=experience.goal)
                    except Exception:
                        pass
            except Exception as e:
                LoggingUtils.log_warning("ExperienceMemory", "Failed to calculate similarity for experience {exp_id}: {error}", 
                                        exp_id=experience.id, error=e)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_experiences.sort(key=lambda x: x.similarity_score or 0, reverse=True)
        LoggingUtils.log_info("ExperienceMemory", "Found {count} similar experiences for goal: {goal}", 
                             count=len(similar_experiences), goal=goal)
        return similar_experiences
    
    def _calculate_similarity(self, goal1: str, goal2: str) -> float:
        """ä½¿ç”¨LLMè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        if not self.llm:
            # å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦
            return self._simple_text_similarity(goal1, goal2)
        
        try:
            prompt = f"""
            è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªä»»åŠ¡æ˜¯å¦ä¸ºâ€œç›¸ä¼¼ä»»åŠ¡â€ï¼Œå¹¶è¿”å›0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ1è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼Œ0è¡¨ç¤ºå®Œå…¨æ— å…³ï¼‰ã€‚

            åˆ¤æ–­æ ‡å‡†ï¼š
1. æ ¸å¿ƒç›®æ ‡æ˜¯å¦ä¸€è‡´ï¼šæœ€ç»ˆè¦è¾¾æˆçš„ç»“æœæ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œå‘é€æ¶ˆæ¯â€å’Œâ€œæäº¤ä¿¡æ¯â€ç›®æ ‡ä¸åŒï¼›â€œå‘é€æ¶ˆæ¯â€å’Œâ€œå‘é€ä¸€æ¡æ–‡æœ¬â€ç›®æ ‡ä¸€è‡´ï¼‰ï¼›
2. å…³é”®å¯¹è±¡æ˜¯å¦ä¸€è‡´ï¼šä»»åŠ¡æ“ä½œçš„æ ¸å¿ƒå®ä½“æ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œç»™å¼ ä¸‰å‘æ¶ˆæ¯â€å’Œâ€œç»™æå››å‘æ¶ˆæ¯â€çš„å…³é”®å¯¹è±¡éƒ½æ˜¯â€œæ¶ˆæ¯â€ï¼Œä¸€è‡´ï¼›â€œå‘æ¶ˆæ¯â€å’Œâ€œä¼ æ–‡ä»¶â€çš„å…³é”®å¯¹è±¡ä¸åŒï¼‰ï¼›
3. æ ¸å¿ƒæ“ä½œæ˜¯å¦ä¸€è‡´ï¼šå®Œæˆä»»åŠ¡çš„æ ¸å¿ƒåŠ¨ä½œæ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œå‘é€æ¶ˆæ¯â€å’Œâ€œæäº¤æ¶ˆæ¯â€çš„æ ¸å¿ƒæ“ä½œéƒ½æ˜¯â€œå‘é€/æäº¤â€ï¼Œä¸€è‡´ï¼›â€œåˆ é™¤æ¶ˆæ¯â€å’Œâ€œè½¬å‘æ¶ˆæ¯â€æ“ä½œä¸åŒï¼‰ã€‚

å¿½ç•¥å‚æ•°å·®å¼‚ï¼ˆå¦‚â€œç»™å¼ ä¸‰å‘æ¶ˆæ¯â€å’Œâ€œç»™æå››å‘æ¶ˆæ¯â€ä»…å‚æ•°ä¸åŒï¼Œè§†ä¸ºé«˜ç›¸ä¼¼åº¦ï¼‰ï¼Œä¹Ÿå¿½ç•¥è¡¨é¢è¡¨è¾¾å·®å¼‚ï¼ˆå¦‚åŒä¹‰è¯ã€å¥å¼å˜åŒ–ï¼‰ã€‚

            ä»»åŠ¡1: {goal1}
            ä»»åŠ¡2: {goal2}

            è¯·åªè¿”å›ä¸€ä¸ª0-1ä¹‹é—´çš„æ•°å­—ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¾‹å¦‚0.95ã€1.00ã€0.30ï¼š
            """
            response = self.llm.complete(prompt)
            similarity_text = response.text.strip()
            
            # å°è¯•æå–æ•°å­—

            numbers = re.findall(r'0\.\d+|1\.0|0|1', similarity_text)
            if numbers:
                similarity = float(numbers[0])
                return max(0.0, min(1.0, similarity))  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
            else:
                LoggingUtils.log_warning("ExperienceMemory", "Could not parse similarity score from: {text}", 
                                        text=similarity_text)
                return self._simple_text_similarity(goal1, goal2)
                
        except Exception as e:
            LoggingUtils.log_warning("ExperienceMemory", "LLM similarity calculation failed: {error}", error=e)
            return self._simple_text_similarity(goal1, goal2)

    def batch_find_similar_experiences(self, goal: str, task_type: str, threshold: float = 0.8) -> List[TaskExperience]:
        """æŸ¥æ‰¾ç›¸ä¼¼ç»éªŒ - ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰åŒ¹é…"""
        if not self.llm:
            LoggingUtils.log_warning("ExperienceMemory", "No LLM provided for batch similarity matching")
            return []

        # æ”¹æˆç»éªŒæŒ‰ç…§åŠŸèƒ½å­˜åœ¨ä¸åŒæ–‡ä»¶å¤¹ï¼Œç›´æ¥è°ƒç”¨
        type_experiences = self.type_experience_cache.get(task_type)

        # å®æ—¶éå†æ‰€æœ‰ç»éªŒï¼Œç­›é€‰å‡ºç±»å‹åŒ¹é…çš„ç»éªŒ.
        # type_experiences = [
        #     exp for exp in self.experiences
        #     if hasattr(exp, 'type') and exp.type == task_type  # æ£€æŸ¥ç»éªŒæ˜¯å¦æœ‰typeå±æ€§ï¼Œä¸”ä¸ä»»åŠ¡ç±»å‹ä¸€è‡´
        # ]
        if not type_experiences:
            LoggingUtils.log_info("ExperienceMemory", f"No experiences found for type: {task_type}")
            return []  #è¿”å›ç©ºåˆ—è¡¨ï¼Œåç»­ç›´æ¥å†·å¯åŠ¨

        # è®°å½•ç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åºå¼€å§‹æ—¶é—´
        llm_start_time = time.time()
        start_timestamp = time.strftime("%H:%M:%S", time.localtime())
        LoggingUtils.log_info(
                "ExperienceMemory",
                f"ğŸ¤” å¼€å§‹ç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åº at {start_timestamp}"
        )

        type_experiences_goals = [exp.goal for exp in type_experiences]
        similarity_scores = self._batch_calculate_similarity(goal, type_experiences_goals)

        similar_experiences = []

        # all_experiences_goals = [exp.goal for exp in self.experiences]
        # similarity_scores = self._batch_calculate_similarity(goal, all_experiences_goals)

        for i, experience in enumerate(type_experiences):
            try:
                similarity = similarity_scores[i]
                # è®°å½•ç›¸ä¼¼åº¦æ—¥å¿—
                try:
                    LoggingUtils.log_debug("ExperienceMemory",
                                       "Similarity calculation: {similarity:.2f} threshold={threshold:.2f} goal={goal}",
                                       similarity=similarity, threshold=threshold, goal=experience.goal)
                except Exception:
                    pass
                if similarity >= threshold:
                    experience.similarity_score = similarity
                    similar_experiences.append(experience)
                else:
                    try:
                        LoggingUtils.log_debug("ExperienceMemory",
                                               "Similarity below threshold: {similarity:.2f} < {threshold:.2f} goal={goal}",
                                               similarity=similarity, threshold=threshold, goal=experience.goal)
                    except Exception:
                        pass
            except Exception as e:
                LoggingUtils.log_warning("ExperienceMemory", "Failed to process experience {exp_id}: {error}",
                                         exp_id=experience.id, error=e)
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_experiences.sort(key=lambda x: x.similarity_score or 0, reverse=True)
        LoggingUtils.log_info("ExperienceMemory", "Found {count} similar experiences for goal: {goal}",
                                      count=len(similar_experiences), goal=goal)

        # è®¡ç®—å¹¶è®°å½•ç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åºè€—æ—¶
        thinking_time = time.time() - llm_start_time
        end_timestamp = time.strftime("%H:%M:%S", time.localtime())
        LoggingUtils.log_info(
            "ExperienceMemory",
            f"ğŸ’¡ å®Œæˆç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åº at {end_timestamp}, è€—æ—¶: {thinking_time:.2f}s"
        )

        return similar_experiences

    def _batch_calculate_similarity(self, goal:str, experience_goals:List[str])-> List[float]:
        """æ‰¹é‡è®¡ç®—ç›®æ ‡ä¸æ‰€æœ‰ç»éªŒçš„ç›¸ä¼¼åº¦"""
        if not self.llm:
            return [self._simple_text_similarity(goal, exp_goal) for exp_goal in experience_goals]
        try:
            batch_prompt = f"""
            è¯·åˆ¤æ–­ä»¥ä¸‹ç›®æ ‡ä¸æ¯æ¡ç»éªŒæ˜¯å¦ä¸ºâ€œç›¸ä¼¼ä»»åŠ¡â€ï¼Œå¹¶ä¸ºæ¯æ¡ç»éªŒè¿”å›0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ1è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼Œ0è¡¨ç¤ºå®Œå…¨æ— å…³ï¼‰ã€‚
            
            åˆ¤æ–­æ ‡å‡†ï¼š
1. æ ¸å¿ƒç›®æ ‡æ˜¯å¦ä¸€è‡´ï¼šæœ€ç»ˆè¦è¾¾æˆçš„ç»“æœæ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œå‘é€æ¶ˆæ¯â€å’Œâ€œæäº¤ä¿¡æ¯â€ç›®æ ‡ä¸åŒï¼›â€œå‘é€æ¶ˆæ¯â€å’Œâ€œå‘é€ä¸€æ¡æ–‡æœ¬â€ç›®æ ‡ä¸€è‡´ï¼‰ï¼›
2. å…³é”®å¯¹è±¡æ˜¯å¦ä¸€è‡´ï¼šä»»åŠ¡æ“ä½œçš„æ ¸å¿ƒå®ä½“æ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œç»™å¼ ä¸‰å‘æ¶ˆæ¯â€å’Œâ€œç»™æå››å‘æ¶ˆæ¯â€çš„å…³é”®å¯¹è±¡éƒ½æ˜¯â€œæ¶ˆæ¯â€ï¼Œä¸€è‡´ï¼›â€œå‘æ¶ˆæ¯â€å’Œâ€œä¼ æ–‡ä»¶â€çš„å…³é”®å¯¹è±¡ä¸åŒï¼‰ï¼›
3. æ ¸å¿ƒæ“ä½œæ˜¯å¦ä¸€è‡´ï¼šå®Œæˆä»»åŠ¡çš„æ ¸å¿ƒåŠ¨ä½œæ˜¯å¦ç›¸åŒï¼ˆå¦‚â€œå‘é€æ¶ˆæ¯â€å’Œâ€œæäº¤æ¶ˆæ¯â€çš„æ ¸å¿ƒæ“ä½œéƒ½æ˜¯â€œå‘é€/æäº¤â€ï¼Œä¸€è‡´ï¼›â€œåˆ é™¤æ¶ˆæ¯â€å’Œâ€œè½¬å‘æ¶ˆæ¯â€æ“ä½œä¸åŒï¼‰ã€‚

å¿½ç•¥å‚æ•°å·®å¼‚ï¼ˆå¦‚â€œç»™å¼ ä¸‰å‘æ¶ˆæ¯â€å’Œâ€œç»™æå››å‘æ¶ˆæ¯â€ä»…å‚æ•°ä¸åŒï¼Œè§†ä¸ºé«˜ç›¸ä¼¼åº¦ï¼‰ï¼Œä¹Ÿå¿½ç•¥è¡¨é¢è¡¨è¾¾å·®å¼‚ï¼ˆå¦‚åŒä¹‰è¯ã€å¥å¼å˜åŒ–ï¼‰ã€‚

            ç›®æ ‡ä»»åŠ¡: {goal}

è¯·ä¸ºä»¥ä¸‹æ¯æ¡ç»éªŒè¿”å›ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰ï¼Œæ ¼å¼ä¸ºâ€œç»éªŒX: åˆ†æ•°â€ï¼ˆä¾‹å¦‚â€œç»éªŒ1: 0.95â€ï¼‰ï¼š
            
            """
            for i, exp_goal in enumerate(experience_goals, 1):
                batch_prompt += f"ç»éªŒ{i}: {exp_goal}\n"
            batch_prompt += "\nè¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ é¢å¤–è§£é‡Šï¼Œç¡®ä¿åˆ†æ•°ä¸ç»éªŒé¡ºåºä¸€ä¸€å¯¹åº”ã€‚"

            response = self.llm.complete(batch_prompt)
            similarity_text = response.text.strip()

            scores = []
            for line in similarity_text.splitlines():
                line = line.strip()
                if not line:
                    continue
                match = re.match(r'ç»éªŒ\d+:\s*(\d+\.\d+|\d+)', line)
                if match:
                    try:
                        score = float(match.group(1))
                        scores.append(max(0.0, min(1.0, score)))
                    except ValueError:
                        scores.append(0.0)
            while len(scores) < len(experience_goals):
                scores.append(0.0)
            return scores[:len(experience_goals)]
        except Exception as e:
            LoggingUtils.log_warning("ExperienceMemory", "Batch LLM calculation failed, fallback to single calls",
                                     error=e)
            # æ‰¹é‡å¤±è´¥æ—¶ï¼Œé™çº§ä¸ºé€æ¡è®¡ç®—ï¼ˆä¿è¯åŠŸèƒ½å¯ç”¨ï¼‰
            return [self._calculate_similarity(goal, exp_goal) for exp_goal in experience_goals]

    def find_and_rank_similar_experiences(self, goal: str, task_type: str, threshold: float = 0.8) -> List[TaskExperience]:
        """
        åˆå¹¶ä¼˜åŒ–ï¼šä¸€æ¬¡LLMè°ƒç”¨åŒæ—¶å®Œæˆç›¸ä¼¼åº¦è®¡ç®—å’Œæ’åº

        Args:
            goal: ç›®æ ‡ä»»åŠ¡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æŒ‰ç›¸ä¼¼åº¦æ’åºçš„ç»éªŒåˆ—è¡¨ï¼ˆå·²è¿‡æ»¤ä½äºé˜ˆå€¼çš„ï¼‰
        """
        if not self.llm:
            LoggingUtils.log_warning("ExperienceMemory", "No LLM provided for similarity matching")
            return []

        # ç»éªŒæŒ‰ç…§ç±»å‹å­˜åœ¨ä¸åŒæ–‡ä»¶å¤¹ï¼Œç›´æ¥è°ƒç”¨å¯¹åº”ç±»å‹çš„ç»éªŒ
        type_experiences = self.type_experience_cache.get(task_type)

        if not type_experiences:
            return []

        try:
            # è®°å½•LLMæ€è€ƒå¼€å§‹æ—¶é—´
            llm_start_time = time.time()
            start_timestamp = time.strftime("%H:%M:%S", time.localtime())
            LoggingUtils.log_info(
                "ExperienceMemory",
                f"ğŸ¤” LLM å¼€å§‹ç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åº at {start_timestamp}"
            )

            # æ„å»ºåˆå¹¶çš„æç¤ºè¯ï¼šåŒæ—¶è®¡ç®—ç›¸ä¼¼åº¦å’Œæ’åº
            prompt = f"""
è¯·åˆ¤æ–­ç›®æ ‡ä»»åŠ¡ä¸ä»¥ä¸‹æ¯æ¡å†å²ç»éªŒçš„ç›¸ä¼¼åº¦ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦ä»é«˜åˆ°ä½æ’åºã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
1. æ ¸å¿ƒç›®æ ‡æ˜¯å¦ä¸€è‡´ï¼šæœ€ç»ˆè¦è¾¾æˆçš„ç»“æœæ˜¯å¦ç›¸åŒ
2. å…³é”®å¯¹è±¡æ˜¯å¦ä¸€è‡´ï¼šä»»åŠ¡æ“ä½œçš„æ ¸å¿ƒå®ä½“æ˜¯å¦ç›¸åŒ
3. æ ¸å¿ƒæ“ä½œæ˜¯å¦ä¸€è‡´ï¼šå®Œæˆä»»åŠ¡çš„æ ¸å¿ƒåŠ¨ä½œæ˜¯å¦ç›¸åŒ

å¿½ç•¥å‚æ•°å·®å¼‚å’Œè¡¨é¢è¡¨è¾¾å·®å¼‚ã€‚

ç›®æ ‡ä»»åŠ¡: {goal}

å†å²ç»éªŒåˆ—è¡¨ï¼š
"""
            for i, exp in enumerate(type_experiences, 1):
                prompt += f"{i}. {exp.goal}\n"

            prompt += f"""
è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«æ¯æ¡ç»éªŒçš„ç›¸ä¼¼åº¦åˆ†æ•°å’Œæ’åºï¼š
{{
    "ranked_experiences": [
        {{"index": 1, "similarity": 0.95, "reason": "ç®€çŸ­ç†ç”±"}},
        {{"index": 3, "similarity": 0.85, "reason": "ç®€çŸ­ç†ç”±"}},
        ...
    ]
}}

è¦æ±‚ï¼š
1. åªè¿”å›ç›¸ä¼¼åº¦ >= {threshold} çš„ç»éªŒ
2. æŒ‰ç›¸ä¼¼åº¦ä»é«˜åˆ°ä½æ’åº
3. index æ˜¯å†å²ç»éªŒåˆ—è¡¨ä¸­çš„åºå·ï¼ˆ1-{len(type_experiences)}ï¼‰
4. similarity æ˜¯ 0-1 ä¹‹é—´çš„åˆ†æ•°ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰
5. reason æ§åˆ¶åœ¨15å­—ä»¥å†…
"""

            LoggingUtils.log_info("ExperienceMemory",
                                "ğŸš€ Merged LLM call: calculating similarity and ranking for {count} experiences",
                                count=len(type_experiences))

            response = self.llm.complete(prompt)
            response_text = response.text.strip()

            # è§£æJSONå“åº”
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if not json_match:
                LoggingUtils.log_warning("ExperienceMemory", "Could not parse JSON from merged response, fallback to batch method")
                return self.batch_find_similar_experiences(goal, task_type, threshold)

            result = json.loads(json_match.group())
            ranked_list = result.get("ranked_experiences", [])

            # æ„å»ºç»“æœåˆ—è¡¨
            similar_experiences = []
            for item in ranked_list:
                idx = item.get("index", 0) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
                similarity = item.get("similarity", 0.0)
                reason = item.get("reason", "")

                if 0 <= idx < len(type_experiences) and similarity >= threshold:
                    exp = type_experiences[idx]
                    exp.similarity_score = similarity
                    similar_experiences.append(exp)
                    LoggingUtils.log_debug("ExperienceMemory",
                                         "âœ“ Matched: {goal} (similarity={score:.2f}, reason={reason})",
                                         goal=exp.goal, score=similarity, reason=reason)

            LoggingUtils.log_success("ExperienceMemory",
                                   "âœ… Merged call completed: found {count} similar experiences in 1 LLM call (saved {saved} calls)",
                                   count=len(similar_experiences),
                                   saved=len(type_experiences))
            # è®¡ç®—å¹¶è®°å½•LLMæ€è€ƒè€—æ—¶
            thinking_time = time.time() - llm_start_time
            end_timestamp = time.strftime("%H:%M:%S", time.localtime())
            LoggingUtils.log_info(
                "ExperienceMemory",
                f"ğŸ’¡ LLM å®Œæˆç›¸ä¼¼åº¦è®¡ç®—ä¸æ’åº at {end_timestamp}, è€—æ—¶: {thinking_time:.2f}s"
            )
            return similar_experiences

        except Exception as e:
            LoggingUtils.log_warning("ExperienceMemory",
                                   "Merged LLM call failed: {error}, fallback to batch method",
                                   error=e)
            return self.batch_find_similar_experiences(goal, task_type, threshold)

    def _simple_text_similarity(self, goal1: str, goal2: str) -> float:
        """ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆJaccardç›¸ä¼¼åº¦ï¼‰"""
        words1 = set(goal1.lower().split())
        words2 = set(goal2.lower().split())
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def save_experience(self, experience: TaskExperience) -> str:
        """ä¿å­˜ç»éªŒåˆ°å­˜å‚¨"""
        try:
            task_type = experience.type
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿æ–‡ä»¶å¤¹åç§°åˆæ³•
            safe_type_name = re.sub(r'[<>:"/\\|?*]', '_', task_type)
            # æ„å»ºç±»å‹å­æ–‡ä»¶å¤¹è·¯å¾„
            type_dir = os.path.join(self.storage_dir, safe_type_name)
            os.makedirs(type_dir, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶å
            safe_goal = "".join(c if c.isalnum() or c in "._-" else "_" for c in experience.goal)
            filename = f"{safe_goal}_{int(experience.timestamp)}.json"
            filepath = os.path.join(type_dir, filename)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(experience.to_dict(), f, indent=2, ensure_ascii=False)
            
            # æ·»åŠ åˆ°å†…å­˜åˆ—è¡¨
            # self.experiences.append(experience)
            self.type_experience_cache[task_type].append(experience)

            LoggingUtils.log_success("ExperienceMemory", "Experience saved: {path}", path=filepath)
            return filepath
            
        except Exception as e:
            LoggingUtils.log_error("ExperienceMemory", "Failed to save experience: {error}", error=e)
            raise
    
    def adapt_parameters(self, experience: TaskExperience, new_goal: str) -> List[Dict]:
        """å‚æ•°è‡ªé€‚åº” - ä½¿ç”¨LLMè°ƒæ•´åŠ¨ä½œåºåˆ—"""
        if not self.llm:
            LoggingUtils.log_warning("ExperienceMemory", "No LLM provided for parameter adaptation")
            return experience.action_sequence
        
        try:
            prompt = f"""
åŸºäºä»¥ä¸‹å†å²ç»éªŒï¼Œä¸ºæ–°çš„ç›®æ ‡ä»»åŠ¡è°ƒæ•´åŠ¨ä½œåºåˆ—ï¼š

å†å²ç»éªŒç›®æ ‡: {experience.goal}
å†å²åŠ¨ä½œåºåˆ—: {json.dumps(experience.action_sequence, ensure_ascii=False, indent=2)}

æ–°ç›®æ ‡: {new_goal}

**é‡è¦çº¦æŸ**ï¼š
1. åªä¿®æ”¹åŠ¨ä½œçš„å‚æ•°å€¼ï¼ˆå¦‚æ—¥æœŸã€æ–‡æœ¬å†…å®¹ã€ç´¢å¼•ç­‰ï¼‰
2. å¿…é¡»ä¿æŒåŠ¨ä½œçš„é¡ºåºå®Œå…¨ä¸å˜
3. ç‰¹åˆ«æ³¨æ„ï¼šç¡®è®¤æŒ‰é’®ã€æäº¤æŒ‰é’®ã€é¡µé¢è·³è½¬ç­‰æµç¨‹æ§åˆ¶åŠ¨ä½œå¿…é¡»ä¿ç•™
4. å¦‚æœæŸä¸ªåŠ¨ä½œçš„å‚æ•°ä¸éœ€è¦ä¿®æ”¹ï¼Œä¿æŒåŸå€¼ä¸å˜

è¯·åˆ†ææ–°ç›®æ ‡ä¸å†å²ç›®æ ‡çš„å·®å¼‚ï¼Œå¹¶è¿”å›è°ƒæ•´åçš„åŠ¨ä½œåºåˆ—ã€‚
è¿”å›æ ¼å¼åº”è¯¥æ˜¯JSONæ•°ç»„ï¼Œæ¯ä¸ªåŠ¨ä½œåŒ…å«actionå’Œparamså­—æ®µã€‚

è°ƒæ•´åçš„åŠ¨ä½œåºåˆ—ï¼š
"""
            response = self.llm.complete(prompt)
            
            # å°è¯•è§£æJSONå“åº”
            json_match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if json_match:
                adapted_actions = json.loads(json_match.group())
                # ä¿ç•™/å›å¡« description å’Œ specific_behavior å­—æ®µï¼Œä¿è¯ä¸‹æ¸¸ changed_indices æ£€æµ‹å¯ç”¨
                try:
                    original_actions = experience.action_sequence or []
                    for i, a in enumerate(adapted_actions or []):
                        if isinstance(a, dict):
                            if 0 <= i < len(original_actions):
                                # å›å¡« description
                                if "description" not in a:
                                    desc = (original_actions[i] or {}).get("description")
                                    if desc:
                                        a["description"] = desc
                                # å›å¡« specific_behavior
                                if "specific_behavior" not in a:
                                    specific_behavior = (original_actions[i] or {}).get("specific_behavior")
                                    if specific_behavior is not None:  # å…è®¸ None å€¼
                                        a["specific_behavior"] = specific_behavior
                except Exception:
                    pass
                LoggingUtils.log_progress("ExperienceMemory", "Parameters adapted for new goal: {goal}", goal=new_goal)
                return adapted_actions
            else:
                LoggingUtils.log_warning("ExperienceMemory", "Could not parse adapted actions from LLM response")
                return experience.action_sequence
                
        except Exception as e:
            LoggingUtils.log_warning("ExperienceMemory", "Parameter adaptation failed: {error}", error=e)
            return experience.action_sequence
    
    def get_experience_by_id(self, experience_id: str) -> Optional[TaskExperience]:
        """æ ¹æ®IDè·å–ç»éªŒ"""
        # for exp in self.experiences:
        #     if exp.id == experience_id:
        #         return exp
        # return None
        for experiences in self.type_experience_cache.values():  # éå†æ‰€æœ‰ç±»å‹çš„ç»éªŒåˆ—è¡¨
            for exp in experiences:
                if exp.id == experience_id:  # åŒ¹é…å”¯ä¸€ID
                    return exp
        return None  # æœªæ‰¾åˆ°æ—¶è¿”å›None

    def get_all_experiences(self) -> List[TaskExperience]:
        """è·å–æ‰€æœ‰ç»éªŒ"""
        # return self.experiences.copy()
        all_experiences = []
        # éå†æ‰€æœ‰ç±»å‹çš„ç¼“å­˜ï¼Œæ±‡æ€»æ‰€æœ‰ç»éªŒ
        for experiences in self.type_experience_cache.values():
            all_experiences.extend(experiences)
        return all_experiences.copy()  # è¿”å›å‰¯æœ¬ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹ç¼“å­˜

    def clear_experiences(self):
        """æ¸…ç©ºæ‰€æœ‰ç»éªŒ"""
        # self.experiences = []
        # # æ¸…ç©ºå­˜å‚¨ç›®å½•
        # if os.path.exists(self.storage_dir):
        #     for filename in os.listdir(self.storage_dir):
        #         if filename.endswith('.json'):
        #             os.remove(os.path.join(self.storage_dir, filename))
        # logger.info("ğŸ§¹ All experiences cleared")
        # æ¸…ç©ºç¼“å­˜
        self.type_experience_cache.clear()
        # æ¸…ç©ºå­˜å‚¨ç›®å½•
        if os.path.exists(self.storage_dir):
            for root, dirs, files in os.walk(self.storage_dir):
                for filename in files:
                    if filename.endswith('.json'):
                        os.remove(os.path.join(root, filename))
        LoggingUtils.log_info("ExperienceMemory", "ğŸ§¹ All experiences (files + cache) cleared")

    def determine_task_type(self, goal: str) -> Optional[str]:
        """ç”¨å¤§æ¨¡å‹åˆ¤æ–­ä»»åŠ¡ç±»å‹ï¼Œå¿…é¡»å±äºæ”¯æŒçš„ç±»å‹æ¸…å•"""
        # è®°å½• LLM æ€è€ƒå¼€å§‹æ—¶é—´
        llm_start_time = time.time()
        start_timestamp = time.strftime("%H:%M:%S", time.localtime())
        LoggingUtils.log_info(
            "ExperienceMemory",
            f"ğŸ¤” LLM å¼€å§‹æ€è€ƒåˆ¤æ–­ä»»åŠ¡ç±»å‹ at {start_timestamp} "
        )

        try:
            # æ„å»ºç±»å‹åˆ¤æ–­æç¤ºè¯   # è¿™é‡Œéœ€è¦å¯¹æ¥ä¸€ä¸‹
            prompt = f"""
è¯·åˆ¤æ–­ä»¥ä¸‹ä»»åŠ¡å±äºå“ªç§åŠŸèƒ½ç±»å‹ï¼ˆåªèƒ½ä»ç»™å®šçš„ç±»å‹æ¸…å•ä¸­é€‰æ‹©ï¼Œè‹¥éƒ½ä¸ç¬¦åˆåˆ™è¿”å›"æœªçŸ¥"ï¼‰ã€‚

æ”¯æŒçš„ç±»å‹æ¸…å•ï¼š{self.supported_types}  

ä»»åŠ¡ï¼š{goal}

è¯·åªè¿”å›ç±»å‹åç§°ï¼ˆå¦‚"è¯·ä¼‘å‡"ï¼‰ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚è‹¥ä¸å±äºä»»ä½•ç±»å‹ï¼Œè¿”å›"æœªçŸ¥"ã€‚
"""
            response = self.llm.complete(prompt)
            task_type = response.text.strip()

            # è®¡ç®—å¹¶è®°å½• LLM æ€è€ƒè€—æ—¶
            thinking_time = time.time() - llm_start_time
            end_timestamp = time.strftime("%H:%M:%S", time.localtime())
            LoggingUtils.log_info(
                "ExperienceMemory",
                f"ğŸ’¡ LLM å®Œæˆæ€è€ƒåˆ¤æ–­ä»»åŠ¡ç±»å‹ at {end_timestamp}, è€—æ—¶: {thinking_time:.2f}s"
            )

            # æ ¡éªŒè¿”å›çš„ç±»å‹æ˜¯å¦åœ¨æ”¯æŒçš„æ¸…å•å†…
            if task_type in self.supported_types:
                LoggingUtils.log_info("ExperienceMemory", f"Task type '{task_type}'")
                return task_type
            else:
                LoggingUtils.log_info("ExperienceMemory", f"Task type '{task_type}' not in supported list")
                return None
        except Exception as e:
            LoggingUtils.log_error("ExperienceMemory", f"Failed to determine task type: {e}")
            return None