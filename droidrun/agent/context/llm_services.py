"""
LLMæœåŠ¡æ¨¡å— - å°è£…æ‰€æœ‰LLMè°ƒç”¨
"""
from typing import List, Dict, Any, Optional
from llama_index.core.llms.llm import LLM
import json
import re
import logging
import time

logger = logging.getLogger("droidrun")

class LLMServices:
    """LLMæœåŠ¡å°è£…ç±»"""
    
    def __init__(self, llm: LLM):
        self.llm = llm
        logger.info("ğŸ¤– LLMServices initialized")
    
    
#     def analyze_execution_anomaly(self, execution_log: List[Dict]) -> Dict[str, Any]:
#         """åˆ†ææ‰§è¡Œå¼‚å¸¸"""
#         try:
#             prompt = f"""
# åˆ†æä»¥ä¸‹æ‰§è¡Œæ—¥å¿—ï¼Œæ£€æµ‹æ˜¯å¦å­˜åœ¨å¼‚å¸¸ï¼š

# æ‰§è¡Œæ—¥å¿—: {json.dumps(execution_log, ensure_ascii=False, indent=2)}

# è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ï¼š
# {{
#     "has_anomaly": true/false,
#     "anomaly_type": "å¼‚å¸¸ç±»å‹",
#     "confidence": 0.0-1.0,
#     "description": "å¼‚å¸¸æè¿°",
#     "suggestion": "å»ºè®®çš„å›é€€ç­–ç•¥"
# }}
# """
#             response = self.llm.complete(prompt)
            
#             # è§£æJSONå“åº”
#             json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
#             if json_match:
#                 analysis = json.loads(json_match.group())
#                 logger.info(f"ğŸ” LLM execution analysis completed")
#                 return analysis
#             else:
#                 logger.warning("Could not parse anomaly analysis from LLM response")
#                 return {
#                     "has_anomaly": False,
#                     "anomaly_type": "unknown",
#                     "confidence": 0.5,
#                     "description": "Could not parse LLM response",
#                     "suggestion": "Continue with current execution"
#                 }
                
#         except Exception as e:
#             logger.warning(f"LLM anomaly analysis failed: {e}")
#             return {
#                 "has_anomaly": False,
#                 "anomaly_type": "analysis_error",
#                 "confidence": 0.3,
#                 "description": f"Analysis failed: {str(e)}",
#                 "suggestion": "Continue with current execution"
#             }
    
    def extract_page_sequence(self, trajectory: Dict) -> List[Dict]:
        """ä»è½¨è¿¹ä¸­æå–é¡µé¢åºåˆ—"""
        try:
            prompt = f"""
ä»ä»¥ä¸‹æ‰§è¡Œè½¨è¿¹ä¸­æå–é¡µé¢è½¬æ¢åºåˆ—ï¼š

è½¨è¿¹æ•°æ®: {json.dumps(trajectory, ensure_ascii=False, indent=2)}

è¯·è¿”å›é¡µé¢åºåˆ—ï¼Œæ¯ä¸ªé¡µé¢åŒ…å«ï¼š
- page_name: é¡µé¢åç§°
- page_features: é¡µé¢ç‰¹å¾æè¿°
- transition_action: è½¬æ¢åŠ¨ä½œ
- ui_elements: å…³é”®UIå…ƒç´ 

è¿”å›JSONæ ¼å¼çš„æ•°ç»„ï¼š
"""
            response = self.llm.complete(prompt)
            
            # è§£æJSONå“åº”
            json_match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if json_match:
                page_sequence = json.loads(json_match.group())
                logger.info(f"ğŸ“„ Extracted {len(page_sequence)} pages from trajectory")
                return page_sequence
            else:
                logger.warning("Could not parse page sequence from LLM response")
                return []
                
        except Exception as e:
            logger.warning(f"Page sequence extraction failed: {e}")
            return []

    
    def select_best_experience(self, experiences: List[Dict], goal: str) -> Optional[Dict]:
        """é€‰æ‹©æœ€ä½³ç»éªŒ"""
        if not experiences:
            return None
        
        try:
            prompt = f"""
ä»ä»¥ä¸‹ç»éªŒä¸­é€‰æ‹©æœ€é€‚åˆæ–°ç›®æ ‡çš„æœ€ä½³ç»éªŒï¼š

æ–°ç›®æ ‡: {goal}

å¯ç”¨ç»éªŒ:
{json.dumps(experiences, ensure_ascii=False, indent=2)}

è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ï¼š
{{
    "best_experience_index": 0,
    "reason": "é€‰æ‹©ç†ç”±",
    "confidence": 0.0-1.0
}}
"""
            response = self.llm.complete(prompt)
            
            # è§£æJSONå“åº”
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                selection = json.loads(json_match.group())
                best_index = selection.get("best_experience_index", 0)
                if 0 <= best_index < len(experiences):
                    logger.info(f"ğŸ¯ Selected best experience: {selection.get('reason', 'No reason provided')}")
                    return experiences[best_index]
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç»éªŒ
            logger.warning("Could not parse best experience selection, using first experience")
            return experiences[0]
                
        except Exception as e:
            logger.warning(f"Best experience selection failed: {e}")
            return experiences[0] if experiences else None

    def detect_changed_actions(self, experience_goal: str, new_goal: str, actions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMé€šç”¨è¯†åˆ«éœ€è¦å‚æ•°é€‚é…/å¾®å†·å¯åŠ¨çš„åŠ¨ä½œç´¢å¼•ï¼Œä¸¥ç¦é¢†åŸŸè¯ç¡¬ç¼–ç ã€‚

        çº¦æŸï¼š
        - è¿”å›çª—å£çº§ä¸€æ¬¡è§¦å‘ç‚¹ï¼ˆæ‰“å¼€/é€‰æ‹©/ç¡®è®¤é“¾æ¡ä»…è¿”å›ä¸€ä¸ªä»£è¡¨æ€§ç´¢å¼•ï¼‰
        - ä»…è¾“å‡ºJSONï¼Œå­—æ®µï¼š{"changed_indices": [int,...], "reasons": ["..."]}
        - è‹¥LLMä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨ä½œä¸ºå…œåº•
        """
        try:
            # ä¸ºLLMæä¾›ç²¾ç®€ä¸”ç»“æ„åŒ–çš„åŠ¨ä½œè§†å›¾
            simplified_actions = []
            for i, a in enumerate(actions or []):
                simplified_actions.append({
                    "index": i,
                    "action": (a or {}).get("action") or (a or {}).get("name") or "",
                    "params": (a or {}).get("params") or (a or {}).get("parameters") or {},
                    "description": str((a or {}).get("description", ""))[:200]
                })

            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„äººæœºæ“ä½œå·®å¼‚å¯¹é½å™¨ã€‚ç°æœ‰ä¸€ä¸ªå†å²ç»éªŒï¼ˆæ—§ç›®æ ‡ï¼‰ä¸ä¸€ä¸ªæ–°ç›®æ ‡ï¼Œä»¥åŠè¯¥ç»éªŒçš„åŠ¨ä½œåºåˆ—ï¼ˆæ¯æ­¥å«åŠ¨ä½œç±»å‹ã€ç®€è¿°ä¸å‚æ•°æ¦‚è§ˆï¼‰ã€‚
ä»»åŠ¡ï¼šæ‰¾å‡ºé‚£äº›å› ä¸ºæ–°æ—§ç›®æ ‡å·®å¼‚è€Œéœ€è¦â€œå‚æ•°é€‚é…æˆ–é‡åšâ€çš„åŠ¨ä½œç´¢å¼•ï¼Œå¹¶è¿”å›ä»£è¡¨æ€§ç´¢å¼•ã€‚

- åªåŸºäºè¯­ä¹‰å·®å¼‚ä¸åŠ¨ä½œæè¿°è¿›è¡Œåˆ¤æ–­ã€‚
- ä»…è¿”å›JSONï¼Œå­—æ®µï¼š\n{{\n  "changed_indices": [æ•´æ•°æ•°ç»„],\n  "reasons": [æ¯ä¸ªç´¢å¼•å¯¹åº”çš„ç®€çŸ­ç†ç”±ï¼Œä¸éœ€è¦ä½“ç°åŸç›®æ ‡å‚æ•°æ˜¯ä»€ä¹ˆï¼Œåªéœ€è¦æŒ‡å‡ºæ–°ç›®æ ‡å‚æ•°æ˜¯ä»€ä¹ˆå³å¯ã€‚å¦‚æœç†ç”±ä¸­æœ‰æ¶‰åŠåˆ°æ—¥æœŸç­‰è¿›è¡Œï¼Œå°½é‡æŒ‰ç…§å¹´æœˆæ—¥ç»™å‡ºæ—¥æœŸçš„å®Œæ•´ä¿¡æ¯]\n}}\nä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚

æ—§ç›®æ ‡ï¼š{experience_goal}
æ–°ç›®æ ‡ï¼š{new_goal}
åŠ¨ä½œåºåˆ—ï¼ˆç²¾ç®€ï¼‰ï¼š{json.dumps(simplified_actions, ensure_ascii=False)}
"""
            # logger.info(f"[LLM][detect_changed_actions] Prompt:\n{prompt}")
            rsp = self.llm.complete(prompt)
            text = getattr(rsp, 'text', str(rsp))
            logger.info(f"[LLM][detect_changed_actions] Response:\n{text}")
            # è§£æä¸¥æ ¼JSON
            m = re.search(r'\{[\s\S]*\}$', text.strip())
            data = json.loads(m.group()) if m else json.loads(text)
            indices_raw = data.get("changed_indices", [])
            reasons_raw = data.get("reasons", [])
            # è§„èŒƒåŒ–ç´¢å¼•ä¸ºæ•´æ•°ï¼ˆä¿ç•™åŸæœ‰é¡ºåºï¼Œç”¨äºä¸ reasons å¯¹é½ï¼‰
            norm_indices: List[int] = []
            for i in indices_raw:
                try:
                    ii = int(str(i))
                    norm_indices.append(ii)
                except Exception:
                    continue
            # æ„é€  index->reason å¯¹é½è¡¨
            index_reasons = []
            for pos, idx in enumerate(norm_indices):
                reason = reasons_raw[pos] if pos < len(reasons_raw) else ""
                index_reasons.append({"index": idx, "reason": str(reason)})
            # ä¾›æ—§é€»è¾‘ä½¿ç”¨çš„å»é‡æ’åºé›†åˆ
            changed_sorted = sorted(set(norm_indices))
            return {"changed_indices": changed_sorted, "index_reasons": index_reasons, "reasons": reasons_raw}
        except Exception:
            logger.warning("detect_changed_actions: LLMè§£æå¤±è´¥ï¼Œè¿”å›ç©ºé›†åˆä½œä¸ºå…œåº•")
            return {"changed_indices": []}

    def generate_micro_goal(self, action: Dict[str, Any], diffs: Dict[str, Any], new_goal: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆé€šç”¨å¾®å†·å¯åŠ¨å­ç›®æ ‡ï¼š
        - å•å¥ä¸­æ–‡ï¼Œé¢å‘ä¸šåŠ¡ã€å¯æ‰§è¡Œ
        - ç¦æ­¢å‡ºç°ç´¢å¼•/åæ ‡/èµ„æºIDç­‰å®ç°ç»†èŠ‚
        - èšç„¦å½“å‰å­é˜¶æ®µï¼Œé¿å…æ¦‚æ‹¬å…¨æµç¨‹
        - ä¸¥ç¦ä½¿ç”¨ä»»ä½•é¢†åŸŸè¯ç¡¬ç¼–ç ï¼ˆæœ¬å‡½æ•°å†…ä¸å†™æ­»ä»»ä½•å…³é”®è¯ï¼‰
        """
        name = (action or {}).get("action") or (action or {}).get("name") or ""
        desc = str((action or {}).get("description", ""))

        # å°† diffs å‹ç¼©ä¸ºè‡ªç„¶è¯­è¨€æ‘˜è¦ä¾›LLMå‚è€ƒï¼ˆä¸å¼•å…¥é¢†åŸŸè¯åˆ¤æ–­ï¼Œä»…é€ä¼ ï¼‰
        try:
            diffs_text = json.dumps(diffs, ensure_ascii=False)
        except Exception:
            diffs_text = "{}"

        try:
            prompt = f"""
ä½ æ˜¯é€šç”¨çš„äººæœºäº¤äº’å­ç›®æ ‡ç”Ÿæˆå™¨ã€‚åŸºäºç»™å®šåŠ¨ä½œçš„è‡ªç„¶è¯­è¨€æè¿°ã€æ•´ä½“æ–°ä»»åŠ¡ç›®æ ‡ï¼Œä»¥åŠä¸¤è€…ä¹‹é—´çš„è¯­ä¹‰å·®å¼‚æ‘˜è¦ï¼Œä¸ºå½“å‰åŠ¨ä½œæ‰€åœ¨çš„å­æµç¨‹ç”Ÿæˆä¸€ä¸ªâ€œå¯ç›´æ¥æ‰§è¡Œçš„ã€é¢å‘ä¸šåŠ¡çš„ä¸€å¥è¯ç›®æ ‡â€ã€‚

è¦æ±‚ï¼š
- ä»…è¾“å‡ºä¸€è¡Œä¸­æ–‡ï¼Œ20-30å­—å†…ï¼›
- ç¦æ­¢å‡ºç°ç´¢å¼•ã€åæ ‡ã€èµ„æºIDç­‰å®ç°ç»†èŠ‚ï¼›
- åªèšç„¦å½“å‰å­é˜¶æ®µçš„å¯å®Œæˆç›®æ ‡ï¼Œé¿å…è¦†ç›–æ•´ä¸ªæµç¨‹ï¼›
- ç”¨è¯ä¸­ç«‹ï¼Œé¿å…ä¾èµ–ä»»ä½•ç‰¹å®šåº”ç”¨/å­—æ®µåï¼›

åŠ¨ä½œæè¿°ï¼š{desc or name}
æ–°ä»»åŠ¡ç›®æ ‡ï¼š{new_goal}
å·®å¼‚æ‘˜è¦ï¼ˆä¾›å‚è€ƒï¼‰ï¼š{diffs_text}
"""
            logger.info(f"[LLM][generate_micro_goal] Prompt:\n{prompt}")
            rsp = self.llm.complete(prompt)
            text = getattr(rsp, 'text', str(rsp)).strip().splitlines()[0]
            logger.info(f"[LLM][generate_micro_goal] Text:\n{text}")
            # å…œåº•ï¼šè‹¥è¿”å›ç©ºæˆ–åŒ…å«æ˜æ˜¾å®ç°ç»†èŠ‚ï¼Œé€€å›åˆ°æ›´æ³›åŒ–çš„å­é˜¶æ®µè¡¨è¾¾
            if not text:
                raise ValueError("empty micro goal")
            if any(k in text for k in ("index", "åæ ‡", "resource-id", "id=", "@id/")):
                raise ValueError("goal contains low-level detail")
            return text
        except Exception:
            # æœ€å°å…œåº•ï¼šè¿”å›åŠ¨ä½œæè¿°æˆ–ææ³›åŒ–çŸ­å¥ï¼Œä¿æŒé€šç”¨
            return desc or "å®Œæˆè¯¥çª—å£çš„å½“å‰å­é˜¶æ®µ"
    
#     def generate_fallback_strategy(self, anomaly_type: str, anomaly_details: Dict) -> str:
#         """ç”Ÿæˆå›é€€ç­–ç•¥"""
#         try:
#             prompt = f"""
# åŸºäºä»¥ä¸‹å¼‚å¸¸ä¿¡æ¯ï¼Œç”Ÿæˆå…·ä½“çš„å›é€€ç­–ç•¥ï¼š

# å¼‚å¸¸ç±»å‹: {anomaly_type}
# å¼‚å¸¸è¯¦æƒ…: {json.dumps(anomaly_details, ensure_ascii=False, indent=2)}

# è¯·æä¾›å…·ä½“çš„å›é€€ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
# 1. å›é€€æ­¥éª¤
# 2. å‚æ•°è°ƒæ•´
# 3. é¢„æœŸç»“æœ

# å›é€€ç­–ç•¥ï¼š
# """
#             response = self.llm.complete(prompt)
#             strategy = response.text.strip()
#             logger.info(f"ğŸ”„ Generated fallback strategy for {anomaly_type}")
#             return strategy
            
#         except Exception as e:
#             logger.warning(f"Fallback strategy generation failed: {e}")
#             return f"Default fallback strategy for {anomaly_type}"
    
#     def validate_ui_state(self, ui_state: Dict, expected_elements: List[str]) -> Dict[str, Any]:
#         """éªŒè¯UIçŠ¶æ€"""
#         try:
#             prompt = f"""
# éªŒè¯å½“å‰UIçŠ¶æ€æ˜¯å¦åŒ…å«æœŸæœ›çš„å…ƒç´ ï¼š

# å½“å‰UIçŠ¶æ€: {json.dumps(ui_state, ensure_ascii=False, indent=2)}
# æœŸæœ›å…ƒç´ : {expected_elements}

# è¯·è¿”å›JSONæ ¼å¼ï¼š
# {{
#     "is_valid": true/false,
#     "found_elements": ["æ‰¾åˆ°çš„å…ƒç´ "],
#     "missing_elements": ["ç¼ºå¤±çš„å…ƒç´ "],
#     "confidence": 0.0-1.0,
#     "suggestion": "å»ºè®®"
# }}
# """
#             response = self.llm.complete(prompt)
            
#             # è§£æJSONå“åº”
#             json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
#             if json_match:
#                 validation = json.loads(json_match.group())
#                 logger.info(f"âœ… UI state validation completed")
#                 return validation
#             else:
#                 logger.warning("Could not parse UI validation from LLM response")
#                 return {
#                     "is_valid": False,
#                     "found_elements": [],
#                     "missing_elements": expected_elements,
#                     "confidence": 0.3,
#                     "suggestion": "Could not validate UI state"
#                 }
                
#         except Exception as e:
#             logger.warning(f"UI state validation failed: {e}")
#             return {
#                 "is_valid": False,
#                 "found_elements": [],
#                 "missing_elements": expected_elements,
#                 "confidence": 0.3,
#                 "suggestion": f"Validation failed: {str(e)}"
#             }