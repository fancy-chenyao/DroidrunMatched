"""
LLMæœåŠ¡æ¨¡å— - å°è£…æ‰€æœ‰LLMè°ƒç”¨
"""
# æ ‡å‡†åº“å¯¼å…¥
import json
import re
from typing import Any, Dict, List, Optional
from droidrun.agent.utils.logging_utils import LoggingUtils

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
from llama_index.core.llms.llm import LLM

class LLMServices:
    """LLMæœåŠ¡å°è£…ç±»"""
    
    def __init__(self, llm: LLM):
        self.llm = llm
        LoggingUtils.log_info("LLMServices", "LLMServices initialized")
    
    
#     def analyze_execution_anomaly(self, execution_log: List[Dict]) -> Dict[str, Any]:
#         """åˆ†ææ‰§è¡Œå¼‚å¸¸"""
#         try:
#             prompt = f"""
# åˆ†æä»¥ä¸‹æ‰§è¡Œæ—¥å¿—ï¼Œæ£€æµ‹æ˜¯å¦å­˜åœ¨å¼‚å¸¸ï¼š

# æ‰§è¡Œæ—¥å¿—: {json.dumps(execution_log, ensure_ascii=False, indent=2)}

# è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ï¼š
# {{
#     "has_anomaly": true/false,
#     "anomaly_type": "å¼‚å¸¸ç±»å‹",
#     "confidence": 0.0-1.0,
#     "description": "å¼‚å¸¸æè¿°",
#     "suggestion": "å»ºè®®çš„å›é€€ç­–ç•¥"
# }}
# """
#             response = self.llm.complete(prompt)
            
#             # è§£æJSONå“åº”
#             json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
#             if json_match:
#                 analysis = json.loads(json_match.group())
#                 logger.info(f"ğŸ” LLM execution analysis completed")
#                 return analysis
#             else:
#                 logger.warning("Could not parse anomaly analysis from LLM response")
#                 return {
#                     "has_anomaly": False,
#                     "anomaly_type": "unknown",
#                     "confidence": 0.5,
#                     "description": "Could not parse LLM response",
#                     "suggestion": "Continue with current execution"
#                 }
                
#         except Exception as e:
#             logger.warning(f"LLM anomaly analysis failed: {e}")
#             return {
#                 "has_anomaly": False,
#                 "anomaly_type": "analysis_error",
#                 "confidence": 0.3,
#                 "description": f"Analysis failed: {str(e)}",
#                 "suggestion": "Continue with current execution"
#             }
    
    def extract_page_sequence(self, trajectory: Dict) -> List[Dict]:
        """ä»è½¨è¿¹ä¸­æå–é¡µé¢åºåˆ—"""
        try:
            prompt = f"""
ä»ä»¥ä¸‹æ‰§è¡Œè½¨è¿¹ä¸­æå–é¡µé¢è½¬æ¢åºåˆ—ï¼š

è½¨è¿¹æ•°æ®: {json.dumps(trajectory, ensure_ascii=False, indent=2)}

è¯·è¿”å›é¡µé¢åºåˆ—ï¼Œæ¯ä¸ªé¡µé¢åŒ…å«ï¼š
- page_name: é¡µé¢åç§°
- page_features: é¡µé¢ç‰¹å¾æè¿°
- transition_action: è½¬æ¢åŠ¨ä½œ
- ui_elements: å…³é”®UIå…ƒç´ 

è¿”å›JSONæ ¼å¼çš„æ•°ç»„ï¼š
"""
            response = self.llm.complete(prompt)
            
            # è§£æJSONå“åº”
            json_match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if json_match:
                page_sequence = json.loads(json_match.group())
                LoggingUtils.log_info("LLMServices", "Extracted {count} pages from trajectory", count=len(page_sequence))
                return page_sequence
            else:
                LoggingUtils.log_warning("LLMServices", "Could not parse page sequence from LLM response")
                return []
                
        except Exception as e:
            LoggingUtils.log_warning("LLMServices", "Page sequence extraction failed: {error}", error=e)
            return []

    
    def _create_experience_summary(self, experience: Dict, index: int) -> Dict:
        """
        åˆ›å»ºç»éªŒçš„ç²¾ç®€æ‘˜è¦ï¼Œç”¨äºLLMé€‰æ‹©
        
        ä¼˜åŒ–ï¼šä»…ä¼ å…¥æ ¸å¿ƒå†³ç­–ä¿¡æ¯ï¼Œç§»é™¤å¤§æ•°æ®å­—æ®µï¼ˆaction_sequenceã€page_sequenceã€ui_statesï¼‰
        Tokenå‡å°‘ï¼š95%+ï¼Œä» ~50,000 é™è‡³ ~1,000
        """
        # ç»Ÿè®¡åŠ¨ä½œç±»å‹åˆ†å¸ƒ
        action_types = {}
        for action in experience.get("action_sequence", []):
            action_type = action.get("action", "unknown")
            action_types[action_type] = action_types.get(action_type, 0) + 1
        
        summary = {
            "index": index,  # ç”¨äºè¿”å›åŸå§‹ç»éªŒçš„ç´¢å¼•
            "goal": experience.get("goal", ""),
            "success": experience.get("success", False),
            "similarity_score": experience.get("similarity_score", 0.0),
            "metadata": {
                "steps": experience.get("metadata", {}).get("steps", 0),
                "execution_time": experience.get("metadata", {}).get("execution_time", 0),
                "is_hot_start": experience.get("metadata", {}).get("is_hot_start", False),
            },
            "statistics": {
                "action_count": len(experience.get("action_sequence", [])),
                "page_count": len(experience.get("page_sequence", [])),
                "action_types": action_types,
            }
        }
        return summary
    
    def select_best_experience(self, experiences: List[Dict], goal: str) -> Optional[Dict]:
        """
        é€‰æ‹©æœ€ä½³ç»éªŒ
        
        ä¼˜åŒ–ï¼šä½¿ç”¨ç²¾ç®€æ‘˜è¦ä»£æ›¿å®Œæ•´æ•°æ®ï¼Œå¤§å¹…å‡å°‘Tokenæ¶ˆè€—ï¼ˆ95%+ï¼‰
        """
        if not experiences:
            return None
        
        try:
            # åˆ›å»ºç²¾ç®€æ‘˜è¦ï¼ˆä»…åŒ…å«æ ¸å¿ƒå†³ç­–ä¿¡æ¯ï¼‰
            summaries = [self._create_experience_summary(exp, i) for i, exp in enumerate(experiences)]
            
            prompt = f"""
ä»ä»¥ä¸‹ç»éªŒæ‘˜è¦ä¸­é€‰æ‹©æœ€é€‚åˆæ–°ç›®æ ‡çš„æœ€ä½³ç»éªŒï¼š

æ–°ç›®æ ‡: {goal}

å¯ç”¨ç»éªŒæ‘˜è¦ï¼ˆå·²ä¼˜åŒ–ï¼Œä»…åŒ…å«æ ¸å¿ƒå†³ç­–ä¿¡æ¯ï¼‰:
{json.dumps(summaries, ensure_ascii=False, indent=2)}

è¯´æ˜ï¼š
- goal: ä»»åŠ¡ç›®æ ‡ï¼ˆæ ¸å¿ƒå†³ç­–ä¾æ®ï¼‰
- success: æ˜¯å¦æˆåŠŸæ‰§è¡Œ
- similarity_score: ä¸æ–°ç›®æ ‡çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
- metadata.steps: æ‰§è¡Œæ­¥éª¤æ•°
- metadata.execution_time: æ‰§è¡Œè€—æ—¶ï¼ˆç§’ï¼‰
- statistics.action_count: åŠ¨ä½œæ•°é‡
- statistics.action_types: åŠ¨ä½œç±»å‹åˆ†å¸ƒ

è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ï¼š
{{
    "best_experience_index": 0,
    "reason": "é€‰æ‹©ç†ç”±ï¼ˆé‡ç‚¹è¯´æ˜ä¸ºä½•è¯¥ç»éªŒæœ€é€‚åˆæ–°ç›®æ ‡ï¼‰",
    "confidence": 0.0-1.0
}}
"""
            LoggingUtils.log_info("LLMServices", "Selecting best from {count} experience summaries (optimized input, ~95% token reduction)", 
                                count=len(summaries))
            response = self.llm.complete(prompt)
            
            # è§£æJSONå“åº”
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                selection = json.loads(json_match.group())
                best_index = selection.get("best_experience_index", 0)
                if 0 <= best_index < len(experiences):
                    LoggingUtils.log_info("LLMServices", "Selected best experience: {reason}", 
                                        reason=selection.get('reason', 'No reason provided'))
                    return experiences[best_index]
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç»éªŒ
            LoggingUtils.log_warning("LLMServices", "Could not parse best experience selection, using first experience")
            return experiences[0]
                
        except Exception as e:
            LoggingUtils.log_warning("LLMServices", "Best experience selection failed: {error}", error=e)
            return experiences[0] if experiences else None

    def detect_changed_actions(self, experience_goal: str, new_goal: str, actions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMé€šç”¨è¯†åˆ«éœ€è¦å‚æ•°é€‚é…/å¾®å†·å¯åŠ¨çš„åŠ¨ä½œç´¢å¼•ï¼Œä¸¥ç¦é¢†åŸŸè¯ç¡¬ç¼–ç ã€‚

        çº¦æŸï¼š
        - è¿”å›çª—å£çº§ä¸€æ¬¡è§¦å‘ç‚¹ï¼ˆæ‰“å¼€/é€‰æ‹©/ç¡®è®¤é“¾æ¡ä»…è¿”å›ä¸€ä¸ªä»£è¡¨æ€§ç´¢å¼•ï¼‰
        - ä»…è¾“å‡ºJSONï¼Œå­—æ®µï¼š{"changed_indices": [int,...], "reasons": ["..."]}
        - è‹¥LLMä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨ä½œä¸ºå…œåº•
        """
        try:
            # ä¸ºLLMæä¾›ç²¾ç®€ä¸”ç»“æ„åŒ–çš„åŠ¨ä½œè§†å›¾
            simplified_actions = []
            for i, a in enumerate(actions or []):
                simplified_actions.append({
                    "index": i,
                    "action": (a or {}).get("action") or (a or {}).get("name") or "",
                    "params": (a or {}).get("params") or (a or {}).get("parameters") or {},
                    "description": str((a or {}).get("description", ""))[:200]
                })

            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„äººæœºæ“ä½œå·®å¼‚å¯¹é½å™¨ã€‚ç°æœ‰ä¸€ä¸ªå†å²ç»éªŒï¼ˆæ—§ç›®æ ‡ï¼‰ä¸ä¸€ä¸ªæ–°ç›®æ ‡ï¼Œä»¥åŠè¯¥ç»éªŒçš„åŠ¨ä½œåºåˆ—ï¼ˆæ¯æ­¥å«åŠ¨ä½œç±»å‹ã€ç®€è¿°ä¸å‚æ•°æ¦‚è§ˆï¼‰ã€‚
ä»»åŠ¡ï¼šæ¯”è¾ƒæ–°æ—§ç›®æ ‡ï¼Œæ‰¾å‡ºåŠ¨ä½œåºåˆ—ä¸­é‚£äº›å› ä¸ºç›®æ ‡å‚æ•°å˜åŒ–è€Œéœ€è¦è°ƒæ•´å‚æ•°æˆ–é‡åšçš„åŠ¨ä½œæ­¥éª¤ç´¢å¼•ã€‚åªè¿”å›è¿™äº›ç´¢å¼•å’Œå¯¹åº”çš„ç®€çŸ­ç†ç”±ã€‚

å…³é”®ç‚¹ï¼š
- åªåŸºäºæ–°æ—§ç›®æ ‡çš„è¯­ä¹‰å·®å¼‚å’ŒåŠ¨ä½œæè¿°è¿›è¡Œåˆ¤æ–­ã€‚
- é‡ç‚¹å…³æ³¨ä¸ç›®æ ‡å‚æ•°ç›´æ¥ç›¸å…³çš„åŠ¨ä½œï¼Œå¦‚è¾“å…¥æ–‡æœ¬ã€é€‰æ‹©æ—¥æœŸã€é€‰æ‹©é€‰é¡¹ç­‰ã€‚
- å¯¹äºæ¯ä¸ªéœ€è¦æ”¹å˜çš„åŠ¨ä½œï¼Œç´¢å¼•åº”åŸºäºåŠ¨ä½œåºåˆ—çš„é¡ºåºï¼ˆä»0å¼€å§‹ï¼‰ã€‚
- ç†ç”±åº”ç®€çŸ­ï¼ŒåªæŒ‡å‡ºæ–°ç›®æ ‡å‚æ•°æ˜¯ä»€ä¹ˆï¼Œä¾‹å¦‚"æ—¥æœŸéœ€è¦æ”¹ä¸º2025å¹´10æœˆ26æ—¥"æˆ–"åœ°åŒºéœ€è¦æ”¹ä¸ºåŒ—äº¬"ã€‚å¦‚æœæ¶‰åŠæ—¥æœŸï¼Œä½¿ç”¨å®Œæ•´å¹´æœˆæ—¥æ ¼å¼ã€‚

ä»…è¿”å›JSONæ ¼å¼ï¼Œå­—æ®µå¦‚ä¸‹ï¼š
{{\n  "changed_indices": [æ•´æ•°æ•°ç»„],\n  "reasons": [å­—ç¬¦ä¸²æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”changed_indicesä¸­ç´¢å¼•çš„ç†ç”±]\n}}
ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ã€‚

æ—§ç›®æ ‡ï¼š{experience_goal}
æ–°ç›®æ ‡ï¼š{new_goal}
åŠ¨ä½œåºåˆ—ï¼ˆç²¾ç®€ï¼‰ï¼š{json.dumps(simplified_actions, ensure_ascii=False)}
"""
            # logger.info(f"[LLM][detect_changed_actions] Prompt:\n{prompt}")
            rsp = self.llm.complete(prompt)
            text = getattr(rsp, 'text', str(rsp))
            LoggingUtils.log_debug("LLMServices", "Detect changed actions response: {text}", text=text)
            # è§£æä¸¥æ ¼JSON
            m = re.search(r'\{[\s\S]*\}$', text.strip())
            data = json.loads(m.group()) if m else json.loads(text)
            indices_raw = data.get("changed_indices", [])
            reasons_raw = data.get("reasons", [])
            # è§„èŒƒåŒ–ç´¢å¼•ä¸ºæ•´æ•°ï¼ˆä¿ç•™åŸæœ‰é¡ºåºï¼Œç”¨äºä¸ reasons å¯¹é½ï¼‰
            norm_indices: List[int] = []
            for i in indices_raw:
                try:
                    ii = int(str(i))
                    norm_indices.append(ii)
                except Exception:
                    continue
            # æ„é€  index->reason å¯¹é½è¡¨
            index_reasons = []
            for pos, idx in enumerate(norm_indices):
                reason = reasons_raw[pos] if pos < len(reasons_raw) else ""
                index_reasons.append({"index": idx, "reason": str(reason)})
            # ä¾›æ—§é€»è¾‘ä½¿ç”¨çš„å»é‡æ’åºé›†åˆ
            changed_sorted = sorted(set(norm_indices))
            return {"changed_indices": changed_sorted, "index_reasons": index_reasons, "reasons": reasons_raw}
        except Exception:
            LoggingUtils.log_warning("LLMServices", "Detect changed actions: LLMè§£æå¤±è´¥ï¼Œè¿”å›ç©ºé›†åˆä½œä¸ºå…œåº•")
            return {"changed_indices": []}

    def generate_micro_goal(self, action: Dict[str, Any], diffs: Dict[str, Any], new_goal: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆé€šç”¨å¾®å†·å¯åŠ¨å­ç›®æ ‡ï¼š
        - å•å¥ä¸­æ–‡ï¼Œé¢å‘ä¸šåŠ¡ã€å¯æ‰§è¡Œ
        - ç¦æ­¢å‡ºç°ç´¢å¼•/åæ ‡/èµ„æºIDç­‰å®ç°ç»†èŠ‚
        - èšç„¦å½“å‰å­é˜¶æ®µï¼Œé¿å…æ¦‚æ‹¬å…¨æµç¨‹
        - ä¸¥ç¦ä½¿ç”¨ä»»ä½•é¢†åŸŸè¯ç¡¬ç¼–ç ï¼ˆæœ¬å‡½æ•°å†…ä¸å†™æ­»ä»»ä½•å…³é”®è¯ï¼‰
        """
        name = (action or {}).get("action") or (action or {}).get("name") or ""
        desc = str((action or {}).get("description", ""))

        # å°† diffs å‹ç¼©ä¸ºè‡ªç„¶è¯­è¨€æ‘˜è¦ä¾›LLMå‚è€ƒï¼ˆä¸å¼•å…¥é¢†åŸŸè¯åˆ¤æ–­ï¼Œä»…é€ä¼ ï¼‰
        try:
            diffs_text = json.dumps(diffs, ensure_ascii=False)
        except Exception:
            diffs_text = "{}"

        try:
            prompt = f"""
ä½ æ˜¯é€šç”¨çš„äººæœºäº¤äº’å­ç›®æ ‡ç”Ÿæˆå™¨ã€‚åŸºäºç»™å®šåŠ¨ä½œçš„è‡ªç„¶è¯­è¨€æè¿°ã€æ•´ä½“æ–°ä»»åŠ¡ç›®æ ‡ï¼Œä»¥åŠä¸¤è€…ä¹‹é—´çš„è¯­ä¹‰å·®å¼‚æ‘˜è¦ï¼Œä¸ºå½“å‰åŠ¨ä½œæ‰€åœ¨çš„å­æµç¨‹ç”Ÿæˆä¸€ä¸ªâ€œå¯ç›´æ¥æ‰§è¡Œçš„ã€é¢å‘ä¸šåŠ¡çš„ä¸€å¥è¯ç›®æ ‡â€ã€‚

è¦æ±‚ï¼š
- ä»…è¾“å‡ºä¸€è¡Œä¸­æ–‡ï¼Œ20-30å­—å†…ï¼›
- ç¦æ­¢å‡ºç°ç´¢å¼•ã€åæ ‡ã€èµ„æºIDç­‰å®ç°ç»†èŠ‚ï¼›
- åªèšç„¦å½“å‰å­é˜¶æ®µçš„å¯å®Œæˆç›®æ ‡ï¼Œé¿å…è¦†ç›–æ•´ä¸ªæµç¨‹ï¼›
- ç”¨è¯ä¸­ç«‹ï¼Œé¿å…ä¾èµ–ä»»ä½•ç‰¹å®šåº”ç”¨/å­—æ®µåï¼›

åŠ¨ä½œæè¿°ï¼š{desc or name}
æ–°ä»»åŠ¡ç›®æ ‡ï¼š{new_goal}
å·®å¼‚æ‘˜è¦ï¼ˆä¾›å‚è€ƒï¼‰ï¼š{diffs_text}
"""
            LoggingUtils.log_debug("LLMServices", "Generate micro goal prompt: {prompt}", prompt=prompt)
            rsp = self.llm.complete(prompt)
            text = getattr(rsp, 'text', str(rsp)).strip().splitlines()[0]
            LoggingUtils.log_debug("LLMServices", "Generate micro goal text: {text}", text=text)
            # å…œåº•ï¼šè‹¥è¿”å›ç©ºæˆ–åŒ…å«æ˜æ˜¾å®ç°ç»†èŠ‚ï¼Œé€€å›åˆ°æ›´æ³›åŒ–çš„å­é˜¶æ®µè¡¨è¾¾
            if not text:
                raise ValueError("empty micro goal")
            if any(k in text for k in ("index", "åæ ‡", "resource-id", "id=", "@id/")):
                raise ValueError("goal contains low-level detail")
            return text
        except Exception:
            # æœ€å°å…œåº•ï¼šè¿”å›åŠ¨ä½œæè¿°æˆ–ææ³›åŒ–çŸ­å¥ï¼Œä¿æŒé€šç”¨
            return desc or "å®Œæˆè¯¥çª—å£çš„å½“å‰å­é˜¶æ®µ"
    
#     def generate_fallback_strategy(self, anomaly_type: str, anomaly_details: Dict) -> str:
#         """ç”Ÿæˆå›é€€ç­–ç•¥"""
#         try:
#             prompt = f"""
# åŸºäºä»¥ä¸‹å¼‚å¸¸ä¿¡æ¯ï¼Œç”Ÿæˆå…·ä½“çš„å›é€€ç­–ç•¥ï¼š

# å¼‚å¸¸ç±»å‹: {anomaly_type}
# å¼‚å¸¸è¯¦æƒ…: {json.dumps(anomaly_details, ensure_ascii=False, indent=2)}

# è¯·æä¾›å…·ä½“çš„å›é€€ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
# 1. å›é€€æ­¥éª¤
# 2. å‚æ•°è°ƒæ•´
# 3. é¢„æœŸç»“æœ

# å›é€€ç­–ç•¥ï¼š
# """
#             response = self.llm.complete(prompt)
#             strategy = response.text.strip()
#             logger.info(f"ğŸ”„ Generated fallback strategy for {anomaly_type}")
#             return strategy
            
#         except Exception as e:
#             logger.warning(f"Fallback strategy generation failed: {e}")
#             return f"Default fallback strategy for {anomaly_type}"
    
#     def validate_ui_state(self, ui_state: Dict, expected_elements: List[str]) -> Dict[str, Any]:
#         """éªŒè¯UIçŠ¶æ€"""
#         try:
#             prompt = f"""
# éªŒè¯å½“å‰UIçŠ¶æ€æ˜¯å¦åŒ…å«æœŸæœ›çš„å…ƒç´ ï¼š

# å½“å‰UIçŠ¶æ€: {json.dumps(ui_state, ensure_ascii=False, indent=2)}
# æœŸæœ›å…ƒç´ : {expected_elements}

# è¯·è¿”å›JSONæ ¼å¼ï¼š
# {{
#     "is_valid": true/false,
#     "found_elements": ["æ‰¾åˆ°çš„å…ƒç´ "],
#     "missing_elements": ["ç¼ºå¤±çš„å…ƒç´ "],
#     "confidence": 0.0-1.0,
#     "suggestion": "å»ºè®®"
# }}
# """
#             response = self.llm.complete(prompt)
            
#             # è§£æJSONå“åº”
#             json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
#             if json_match:
#                 validation = json.loads(json_match.group())
#                 logger.info(f"âœ… UI state validation completed")
#                 return validation
#             else:
#                 logger.warning("Could not parse UI validation from LLM response")
#                 return {
#                     "is_valid": False,
#                     "found_elements": [],
#                     "missing_elements": expected_elements,
#                     "confidence": 0.3,
#                     "suggestion": "Could not validate UI state"
#                 }
                
#         except Exception as e:
#             logger.warning(f"UI state validation failed: {e}")
#             return {
#                 "is_valid": False,
#                 "found_elements": [],
#                 "missing_elements": expected_elements,
#                 "confidence": 0.3,
#                 "suggestion": f"Validation failed: {str(e)}"
#             }