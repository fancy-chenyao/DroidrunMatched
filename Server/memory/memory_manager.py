import json
import os
from collections import defaultdict
from typing import Dict

import numpy as np
import pandas as pd

from agents import param_fill_agent, subtask_merge_agent
from memory.page_manager import PageManager
from memory.node_manager import NodeManager
from utils import parsing_utils
from env_config import Config
from utils.mongo_utils import check_connection
from utils.action_utils import generalize_action
from utils.utils import get_openai_embedding, log, safe_literal_eval, cosine_similarity
from utils.mongo_utils import load_dataframe, save_dataframe
from utils.local_store import write_dataframe_csv, read_dataframe_csv
from utils.local_store import write_dataframe_csv


def init_database(path: str, headers: list, use_cache: bool = True):
    # å½“ DB å…³é—­æ—¶ï¼Œä¼˜å…ˆä»æœ¬åœ° CSV è¯»å–ï¼›å¦åˆ™èµ° Mongo é›†åˆ
    if not Config.ENABLE_DB:
        return read_dataframe_csv(path, headers)
    return load_dataframe(path, headers, use_cache=use_cache)


class Memory:
    def __init__(self, instruction: str, task_name: str):

        self.instruction = instruction
        self.task_name = task_name
        self.curr_action_step = 0

        # ä½¿ç”¨ MongoDB é›†åˆä½œä¸ºæŒä¹…åŒ–ç›®æ ‡ï¼Œä¸å†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
        self.task_db_path = "tasks"
        self.page_path = "pages"
        self.screen_hierarchy_path = "hierarchy"
        self.screens_path = "screens"  # ç”¨äºå­˜å‚¨å±å¹•æˆªå›¾å’ŒXMLæ–‡ä»¶

        task_header = ['name', 'path']
        page_header = ['index', 'available_subtasks', 'trigger_uis', 'extra_uis', "screen"]
        hierarchy_header = ['index', 'screen', 'embedding']

        log(f"ğŸ“Š å†…å­˜åˆå§‹åŒ–: ä»»åŠ¡='{task_name}', æŒ‡ä»¤='{instruction[:50]}...'", "blue")

        # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼ˆæœ¬åœ°æ¨¡å¼æŒ‰ä»»åŠ¡ç»´åº¦è¯»å–CSVï¼‰
        if not Config.ENABLE_DB:
            self.task_db = read_dataframe_csv(self.task_db_path, task_header, task_name=self.task_name)
        else:
            self.task_db = init_database(self.task_db_path, task_header, use_cache=True)
        log(f"ğŸ“Š ä»»åŠ¡æ•°æ®åº“åŠ è½½: ä»»åŠ¡æ•°é‡={len(self.task_db)}", "cyan")
        
        if not Config.ENABLE_DB:
            self.page_db = read_dataframe_csv(self.page_path, page_header, task_name=self.task_name)
        else:
            self.page_db = init_database(self.page_path, page_header, use_cache=True)
        self.page_db.set_index('index', drop=False, inplace=True)
        log(f"ğŸ“Š é¡µé¢æ•°æ®åº“åŠ è½½: é¡µé¢æ•°é‡={len(self.page_db)}", "cyan")
        
        if not Config.ENABLE_DB:
            self.hierarchy_db = read_dataframe_csv(self.screen_hierarchy_path, hierarchy_header, task_name=self.task_name)
        else:
            self.hierarchy_db = init_database(self.screen_hierarchy_path, hierarchy_header, use_cache=True)
        self.hierarchy_db['embedding'] = self.hierarchy_db.embedding.apply(safe_literal_eval)
        log(f"ğŸ“Š å±‚çº§æ•°æ®åº“åŠ è½½: å±‚çº§æ•°é‡={len(self.hierarchy_db)}", "cyan")
        
        self.task_path = self.__get_task_data(self.task_name)
        if self.task_path:
            log(f"ğŸ”¥ çƒ­å¯åŠ¨: æ‰¾åˆ°ä»»åŠ¡å†å²è·¯å¾„ï¼Œé¡µé¢æ•°é‡={len(self.task_path)}", "green")
        else:
            log(f"â„ï¸ å†·å¯åŠ¨: æ— ä»»åŠ¡å†å²è·¯å¾„ï¼Œå°†å­¦ä¹ æ–°æµç¨‹", "yellow")
            
        self.page_managers: Dict[int, PageManager] = {}
        self.page_manager = None
        self._cache_dirty = False  # ç¼“å­˜è„æ ‡è®°

    def init_page_manager(self, page_index: int):
        if page_index not in self.page_managers:
            self.page_managers[page_index] = PageManager(self.task_name, page_index)

        self.page_manager = self.page_managers[page_index]

    def search_node(self, parsed_xml, hierarchy_xml, encoded_xml) -> (int, list):
        # candidate_nodes_indexes = self.__search_similar_hierarchy_nodes(hierarchy_xml)
        #
        # node_manager = NodeManager(self.page_db, self, parsed_xml, encoded_xml)
        # node_index, new_subtasks = node_manager.search(candidate_nodes_indexes)
        log(f"ğŸ” é¡µé¢åŒ¹é…æ£€æŸ¥: å†å²é¡µé¢æ•°é‡={len(self.hierarchy_db)}", "blue")
        most_similar_node_index = self.__search_most_similar_hierarchy_node(hierarchy_xml)
        if most_similar_node_index >= 0:
            log(f"ğŸ”¥ çƒ­å¯åŠ¨: é¡µé¢åŒ¹é…æˆåŠŸï¼Œé¡µé¢ç´¢å¼•={most_similar_node_index}", "green")
            return most_similar_node_index, []
        else:
            log(f"â„ï¸ å†·å¯åŠ¨: æœªæ‰¾åˆ°åŒ¹é…çš„å†å²é¡µé¢ï¼Œå°†æ¢ç´¢æ–°ç•Œé¢", "yellow")
            return -1, []

    def get_available_subtasks(self, page_index):
        return self.page_managers[page_index].get_available_subtasks()

    def add_new_action(self, new_action, page_index):
        page_manager = self.page_managers[page_index]
        # 1) å†™å…¥ available_subtasks.csvï¼ˆå·²æœ‰é€»è¾‘ï¼‰
        page_manager.add_new_action(new_action)
        # 2) åŒæ­¥å†™å…¥æœ€å°ç¤ºä¾‹åˆ° subtasks.csvï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
        try:
            subtask_raw = {
                "name": new_action.get("name", "unknown"),
                "description": new_action.get("description", ""),
                "parameters": new_action.get("parameters", {})
            }
            page_manager.save_subtask(subtask_raw, example={})
        except Exception:
            pass
        # 3) ç§»é™¤åŸºç¡€åŠ¨ä½œæ¨¡æ¿ä¿å­˜ï¼Œåªä¿ç•™å…·ä½“æ‰§è¡ŒåŠ¨ä½œ

    def search_node_by_hierarchy(self, parsed_xml, hierarchy_xml, encoded_xml) -> (int, list):
        # 1. First search for at most 5 candidate nodes based only on the hierarchy of the screen
        most_similar_node_index = self.__search_most_similar_hierarchy_node(hierarchy_xml)

        if most_similar_node_index >= 0:
            page_data = json.loads(self.page_db.loc[most_similar_node_index].to_json())
            available_subtasks = json.loads(page_data['available_subtasks'])
            return most_similar_node_index, available_subtasks
        else:
            return -1, []

    def add_node(self, available_subtasks: list, trigger_uis: dict, extra_uis: list, screen: str, screen_num=None) -> int:
        new_index = len(self.page_db)
        new_row = {'index': new_index, 'available_subtasks': json.dumps(available_subtasks),
                   'trigger_uis': json.dumps(trigger_uis),
                   'extra_uis': json.dumps(extra_uis), "screen": screen}
        # å°†æ›´æ–°åçš„é¡µé¢ä¿¡æ¯ä¿å­˜åˆ° MongoDB é›†åˆ
        self.page_db = pd.concat([self.page_db, pd.DataFrame([new_row])], ignore_index=True)
        save_dataframe(self.page_path, self.page_db)
        write_dataframe_csv(self.page_path, self.page_db, task_name=self.task_name)

        # æ ¹æ®é…ç½®ä¸è¿é€šæ€§ï¼šä¼˜å…ˆå†™å…¥æ•°æ®åº“ï¼›ä¸å¯ç”¨æ—¶ä¸å†™DBï¼Œä¿ç•™æœ¬åœ°æ–‡ä»¶
        try:
            if Config.ENABLE_DB and check_connection():
                parsing_utils.save_screen_info_to_mongo(self.task_name, new_index, screen_num)
            else:
                # æœ¬åœ°ä¿å­˜ï¼ˆä¸ Server_origin å¯¹é½ï¼‰ï¼šmemory/log/<task>/pages/<index>/screen/
                try:
                    parsing_utils.save_screen_info_local_aligned(self.task_name, new_index, screen_num)
                except Exception:
                    pass
        except Exception:
            # ä»»ä½•å¼‚å¸¸éƒ½ä¸é˜»æ–­ä¸»æµç¨‹
            pass

        return new_index

    def update_node(self, page_index, new_available_subtasks: list, new_trigger_uis: dict, new_extra_uis: list,
                    new_screen: str):
        page_data = json.loads(self.page_db.loc[page_index].to_json())
        page_data = {key: json.loads(value) if key in ['available_subtasks', 'trigger_uis', 'extra_uis'] else value for
                     key, value in page_data.items()}

        # merge old and new infos
        merged_available_subtasks = page_data['available_subtasks'] + new_available_subtasks
        merged_trigger_uis = {}
        merged_trigger_uis.update(page_data['trigger_uis'])
        merged_trigger_uis.update(new_trigger_uis)
        merged_extra_uis = page_data['extra_uis'] + new_extra_uis

        updated_row = {'index': page_index, 'available_subtasks': json.dumps(merged_available_subtasks),
                       'trigger_uis': json.dumps(merged_trigger_uis),
                       'extra_uis': json.dumps(merged_extra_uis), "screen": new_screen}

        self.page_db.loc[page_index] = updated_row
        save_dataframe(self.page_path, self.page_db)
        write_dataframe_csv(self.page_path, self.page_db, task_name=self.task_name)

        # available_subtasks çš„æŒä¹…åŒ–ç”± PageManager è´Ÿè´£åˆ° MongoDBï¼Œä¸å†å†™ CSV

    def add_hierarchy_xml(self, screen, page_index):
        #  ç”Ÿæˆç•Œé¢XMLçš„åµŒå…¥å‘é‡
        embedding = get_openai_embedding(screen)
        # æ„é€ å±‚çº§æ•°æ®ï¼ˆé¡µé¢ç´¢å¼•ã€XMLã€åµŒå…¥å‘é‡ï¼‰
        new_screen_hierarchy = {'index': page_index, 'screen': screen, 'embedding': str(embedding)}
        # å†™å…¥ç•Œé¢å±‚çº§åº“å¹¶é‡æ–°åŠ è½½ï¼ˆç¡®ä¿åç»­åŒ¹é…å¯ç”¨ï¼‰
        if not Config.ENABLE_DB:
            hierarchy_db = read_dataframe_csv(self.screen_hierarchy_path, ['index', 'screen', 'embedding'], task_name=self.task_name)
        else:
            hierarchy_db = init_database(self.screen_hierarchy_path, ['index', 'screen', 'embedding'])
        
        # è‹¥è¯¥ page_index å·²å­˜åœ¨ï¼Œåˆ™æ›´æ–°ï¼›å¦åˆ™è¿½åŠ ï¼Œä¿è¯â€œæ¯ä¸ªæ–°é¡µé¢ä¸€è¡Œâ€
        if not hierarchy_db.empty and 'index' in hierarchy_db.columns and page_index in set(hierarchy_db['index'].tolist()):
            try:
                mask = (hierarchy_db['index'] == page_index)
                hierarchy_db.loc[mask, 'screen'] = new_screen_hierarchy['screen']
                hierarchy_db.loc[mask, 'embedding'] = new_screen_hierarchy['embedding']
            except Exception:
                hierarchy_db = pd.concat([hierarchy_db, pd.DataFrame([new_screen_hierarchy])], ignore_index=True)
        else:
            hierarchy_db = pd.concat([hierarchy_db, pd.DataFrame([new_screen_hierarchy])], ignore_index=True)
        
        save_dataframe(self.screen_hierarchy_path, hierarchy_db)
        write_dataframe_csv(self.screen_hierarchy_path, hierarchy_db, task_name=self.task_name)

        if not Config.ENABLE_DB:
            self.hierarchy_db = read_dataframe_csv(self.screen_hierarchy_path, ['index', 'screen', 'embedding'], task_name=self.task_name)
        else:
            self.hierarchy_db = init_database(self.screen_hierarchy_path, ['index', 'screen', 'embedding'])
        self.hierarchy_db['embedding'] = self.hierarchy_db.embedding.apply(safe_literal_eval)

    def get_next_subtask(self, page_index, qa_history, screen):
        # Initialize action step
        self.curr_action_step = 0
        # è°ƒç”¨åº”ç”¨çº§task.csv
        candidate_subtasks = self.task_path.get(page_index, [])
        next_subtask_name = None
        # éå†å€™é€‰å­ä»»åŠ¡ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªâ€œæœªæ‰§è¡Œâ€ï¼ˆtraversed = Falseï¼‰çš„å­ä»»åŠ¡
        for subtask in candidate_subtasks:
            if not subtask.get("traversed", False):
                next_subtask_name = subtask.get("name")
                subtask['traversed'] = True # æ ‡è®°ä¸ºâ€œå·²æ‰§è¡Œâ€ï¼Œé¿å…é‡å¤é€‰æ‹©
                break
        # å¤„ç†ç‰¹æ®Šå­ä»»åŠ¡ï¼ˆç»“æŸã€æ»‘åŠ¨ï¼‰
        if next_subtask_name == 'finish':
            finish_subtask = {"name": "finish",
                              "description": "Use this to signal that the task has been completed",
                              "parameters": {}
                              }
            return finish_subtask
        # elif next_subtask_name == "scroll_screen":
        #     scroll_subtask = {"name": "scroll_screen", "parameters": {"scroll_ui_index": 1, "direction": 'down'}}
        #     return scroll_subtask
        # è‹¥æ‰¾åˆ°å­ä»»åŠ¡ï¼Œå¡«å……å‚æ•°ï¼ˆè°ƒç”¨param_fill_agentï¼Œç»“åˆé—®ç­”å†å²ï¼‰,è°ƒç”¨subtasks.csv
        if next_subtask_name:
            next_subtask_data = self.page_manager.get_next_subtask_data(next_subtask_name)

            raw_params = next_subtask_data.get('parameters', {})
            params: dict = {}
            if isinstance(raw_params, dict):
                params = raw_params
            elif isinstance(raw_params, str):
                try:
                    # å…¼å®¹ '"{}"'ã€'' ç­‰æƒ…å†µ
                    if raw_params.strip() == '' or raw_params.strip().strip('"') == '{}':
                        params = {}
                    else:
                        params = json.loads(raw_params)
                except Exception:
                    params = {}
            else:
                params = {}

            next_subtask = {'name': next_subtask_data.get('name', next_subtask_name), 'description': next_subtask_data.get('description', ''),
                            'parameters': params}
            # è‹¥å­ä»»åŠ¡æœ‰å‚æ•°ï¼Œè°ƒç”¨param_fill_agentå¡«å……å‚æ•°ï¼ˆç»“åˆç”¨æˆ·æŒ‡ä»¤ã€é—®ç­”å†å²ã€ç•Œé¢ï¼‰
            if len(next_subtask['parameters']) > 0:
                params = param_fill_agent.parm_fill_subtask(instruction=self.instruction,
                                                            subtask=next_subtask,
                                                            qa_history=qa_history,
                                                            screen=screen,
                                                            example=json.loads(
                                                                next_subtask_data.get('example', {})))

                next_subtask['parameters'] = params

            return next_subtask

        return None

    def save_subtask(self, subtask_raw: dict, example: dict) -> None:
        self.page_manager.save_subtask(subtask_raw, example)

    def get_next_action(self, subtask: dict, screen: str) -> dict:
        next_action = self.page_manager.get_next_action(subtask, screen, self.curr_action_step)
        self.curr_action_step += 1
        log(f":::DERIVE:::", "blue")
        return next_action

    def save_action(self, subtask: dict, action: dict, example=None) -> None:
        if action['name'] == 'finish':
            self.curr_action_step += 1
        self.page_manager.save_action(subtask, self.curr_action_step, action, example)

    def merge_subtasks(self, task_path: list) -> list:
        # Remove finish subtask at the end
        finish_subtask = task_path.pop()

        # Initialize list of subtasks performed.
        raw_subtask_list = []
        for subtask_data in task_path:
            page_index = subtask_data['page_index']
            subtask_name = subtask_data['subtask_name']
            page_data = json.loads(self.page_db.loc[page_index].to_json())
            available_subtasks = json.loads(page_data['available_subtasks'])
            for subtask_available in available_subtasks:
                if subtask_available['name'] == subtask_name:
                    raw_subtask_list.append(subtask_available)

        merged_subtask_list = subtask_merge_agent.merge_subtasks(raw_subtask_list)

        merged_task_path = self.__merge_subtasks_data(task_path, merged_subtask_list)
        # Add Finish subtask at the end back in
        merged_task_path.append(finish_subtask)

        return merged_task_path

    def save_task(self, task_path: list) -> None:
        # éå† task_path ä¸­çš„æ¯ä¸ªå­ä»»åŠ¡ï¼ˆæ¯ä¸ªå­ä»»åŠ¡åŒ…å«å¤šä¸ªåŠ¨ä½œï¼‰
        for subtask in task_path:
            subtask_name = subtask['subtask_name'] # å­ä»»åŠ¡æ‰€å±é¡µé¢ç´¢å¼•
            subtask_dict = subtask['subtask'] # å­ä»»åŠ¡å
            actions = subtask['actions'] # å­ä»»åŠ¡åŒ…å«çš„æ‰€æœ‰åŠ¨ä½œ
            step = 0 # åŠ¨ä½œæ­¥éª¤è®¡æ•°å™¨ï¼ˆæ ‡è®°æ˜¯å­ä»»åŠ¡çš„ç¬¬å‡ æ­¥åŠ¨ä½œï¼‰
            # éå†å½“å‰å­ä»»åŠ¡çš„æ¯ä¸ªåŠ¨ä½œ
            for action_data in actions:
                page_index = action_data['page_index']  # åŠ¨ä½œæ‰§è¡Œæ—¶çš„é¡µé¢ç´¢å¼•
                action = action_data['action']  # å…·ä½“åŠ¨ä½œ
                screen = action_data['screen']  # åŠ¨ä½œæ‰§è¡Œæ—¶çš„ç•Œé¢XML
                example = action_data['example']  # åŠ¨ä½œç¤ºä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºåç»­å¤ç”¨å‚è€ƒï¼‰

                # å…³é”®åˆ¤æ–­ï¼šä»…ä¿å­˜"ç»“æŸåŠ¨ä½œ"æˆ–"å¸¦ç¤ºä¾‹çš„åŠ¨ä½œ"ï¼ˆè¿™äº›åŠ¨ä½œæ›´å…·å¤ç”¨ä»·å€¼ï¼‰
                if action['name'] == 'finish' or example:
                    #  æ³›åŒ–åŠ¨ä½œï¼šå»é™¤ç•Œé¢ä¾èµ–çš„å…·ä½“å€¼ï¼ˆå¦‚å°†å›ºå®šåæ ‡è½¬ä¸ºç›¸å¯¹ä½ç½®ï¼‰
                    # ä¾‹å¦‚ï¼šå°†{"coordinates":[800,900]}è½¬ä¸º{"coordinates":"send_button_position"}
                    generalized_action = generalize_action(action, subtask_dict, screen)
                    page_manager = self.page_managers[page_index]
                    # è°ƒç”¨é¡µé¢ç®¡ç†å™¨ä¿å­˜æ³›åŒ–åçš„åŠ¨ä½œï¼ˆå†™å…¥é¡µé¢ä¸“å±çš„actions.csvï¼‰
                    page_manager.save_action(subtask_name, step, generalized_action, example)
                step += 1

        known_task_path = {
            key: [item["name"] for item in value]
            for key, value in self.task_path.items()
        }

        for subtask in task_path:
            page_index = subtask['page_index']
            subtask_name = subtask['subtask_name']
            if page_index in known_task_path:
                if subtask_name not in known_task_path[page_index]:
                    known_task_path[page_index].append(subtask_name)
            else:
                known_task_path[page_index] = [subtask_name]

        # åˆå¹¶åçš„ä»»åŠ¡è·¯å¾„æŒä¹…åŒ–åˆ°tasks.csvï¼Œå®Œæˆæ•´ä¸ªä»»åŠ¡çš„ â€œè®°å¿†å­˜å‚¨â€
        # æ„é€ æ–°çš„ä»»åŠ¡æ•°æ®ï¼ˆå«ä»»åŠ¡åå’ŒJSONæ ¼å¼çš„è·¯å¾„ï¼‰
        new_task_path = {
            'name': self.task_name,
            'path': json.dumps(known_task_path)
        }
        # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨äºå…¨å±€ä»»åŠ¡åº“ï¼ˆtasks.csvï¼‰
        condition = (self.task_db['name'] == new_task_path['name'])
        if condition.any():
            self.task_db.loc[condition] = pd.DataFrame([new_task_path])
        else:
            self.task_db = pd.concat([self.task_db, pd.DataFrame([new_task_path])], ignore_index=True)
        # å°†æ›´æ–°åçš„ä»»åŠ¡åº“å†™å…¥ MongoDB
        save_dataframe(self.task_db_path, self.task_db)
        write_dataframe_csv(self.task_db_path, self.task_db, task_name=self.task_name)
        log(f":::TASK SAVE::: Path saved: {new_task_path}")

    def save_task_path(self, new_task_path: dict):
        for page_index, subtasks in new_task_path.items():
            if page_index in self.task_path:
                self.task_path[page_index].extend(subtasks)
            else:
                self.task_path[page_index] = subtasks[:]

        new_task_data = {
            'name': self.task_name,
            'path': json.dumps(self.task_path)
        }

        condition = (self.task_db['name'] == new_task_data['name'])
        if condition.any():
            for column in new_task_path.keys():
                self.task_db.loc[condition, column] = new_task_path[column]
        else:
            self.task_db = pd.concat([self.task_db, pd.DataFrame([new_task_data])], ignore_index=True)

        save_dataframe(self.task_db_path, self.task_db)

    def __get_task_data(self, task_name):
        # Search for the task
        matched_tasks = self.task_db[(self.task_db['name'] == task_name)]
        if matched_tasks.empty:
            log(f"â„ï¸ å†·å¯åŠ¨: ä»»åŠ¡ '{task_name}' åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨", "yellow")
            return {}
        else:
            task_data = matched_tasks.iloc[0].to_dict()
            path = json.loads(task_data['path'])

            task_path = {}
            for page_index, subtasks in path.items():
                subtasks_data = []
                for subtask in subtasks:
                    subtasks_data.append({"name": subtask, "traversed": False})
                task_path[int(page_index)] = subtasks_data

            log(f"ğŸ”¥ çƒ­å¯åŠ¨: æ‰¾åˆ°ä»»åŠ¡ '{task_name}' çš„å†å²è·¯å¾„", "green")
            log(f"ğŸ“Š ä»»åŠ¡è·¯å¾„è¯¦æƒ…: {task_path}", "cyan")

            return task_path

    def __search_similar_hierarchy_nodes(self, hierarchy) -> list:
        new_hierarchy_vector = np.array(get_openai_embedding(hierarchy))
        self.hierarchy_db["similarity"] = self.hierarchy_db.embedding.apply(
            lambda x: cosine_similarity(x, new_hierarchy_vector))

        # get top apps with the highest similarity
        candidates = self.hierarchy_db.sort_values('similarity', ascending=False).head(5).to_dict(orient='records')
        candidate_node_indexes = []
        for node in candidates:
            candidate_node_indexes.append(node['index'])

        return candidate_node_indexes

    def __search_most_similar_hierarchy_node(self, hierarchy) -> int:
        new_hierarchy_vector = np.array(get_openai_embedding(hierarchy))
        self.hierarchy_db["similarity"] = self.hierarchy_db.embedding.apply(
            lambda x: cosine_similarity(x, new_hierarchy_vector))

        # get top apps with the highest similarity
        candidates = self.hierarchy_db.sort_values('similarity', ascending=False).head(5).to_dict(orient='records')
        if candidates:
            highest_similarity = candidates[0]['similarity']
            log(f"ğŸ“Š ç›¸ä¼¼åº¦è®¡ç®—: æœ€é«˜ç›¸ä¼¼åº¦={highest_similarity:.4f}, é˜ˆå€¼=0.97", "cyan")
            if highest_similarity > 0.97:
                log(f"âœ… é¡µé¢åŒ¹é…æˆåŠŸ: é¡µé¢ç´¢å¼•={candidates[0]['index']}, ç›¸ä¼¼åº¦={highest_similarity:.4f}", "green")
                return candidates[0]['index']
            else:
                log(f"âŒ é¡µé¢åŒ¹é…å¤±è´¥: ç›¸ä¼¼åº¦{highest_similarity:.4f}ä½äºé˜ˆå€¼0.97", "yellow")
        else:
            log("âŒ é¡µé¢åŒ¹é…å¤±è´¥: æ— å†å²é¡µé¢æ•°æ®", "yellow")
        return -1

    def __merge_subtasks_data(self, original_subtasks_data, merged_subtasks) -> list:
        len_diff = len(original_subtasks_data) - len(merged_subtasks)
        for i in range(0, len_diff):
            merged_subtasks.append({"name": "dummy"})

        original_pointer = 0
        merged_pointer = 0
        while original_pointer < len(original_subtasks_data):
            curr_subtask_data = original_subtasks_data[original_pointer]
            curr_subtask_name = curr_subtask_data['subtask_name']
            curr_subtask_actions = curr_subtask_data['actions']

            merged_subtask_dict = merged_subtasks[merged_pointer]
            if merged_subtask_dict['name'] == curr_subtask_name:
                page_index = curr_subtask_data['page_index']
                page_data = json.loads(self.page_db.loc[page_index].to_json())
                available_subtasks = json.loads(page_data['available_subtasks'])
                # Loop through the available subtasks list and replace the subtask with the new one.
                for i in range(len(available_subtasks)):
                    if available_subtasks[i]['name'] == curr_subtask_name:
                        available_subtasks[i] = merged_subtask_dict

                page_data['available_subtasks'] = json.dumps(available_subtasks)
                self.page_db.loc[page_index] = page_data
                save_dataframe(self.page_path, self.page_db)
                write_dataframe_csv(self.page_path, self.page_db, task_name=self.task_name)

                self.page_managers[page_index].update_subtask_info(merged_subtask_dict)

                merged_subtask_params = merged_subtask_dict['parameters']
                curr_subtask_params = curr_subtask_data['subtask']['parameters']
                for param_name, _ in merged_subtask_params.items():
                    if param_name not in curr_subtask_params:
                        curr_subtask_params[param_name] = None

                original_pointer += 1
                merged_pointer += 1
            else:
                base_subtask_data = original_subtasks_data[original_pointer - 1]
                base_subtask_actions = base_subtask_data['actions']

                base_subtask_params = base_subtask_data['subtask']['parameters']
                curr_subtask_params = curr_subtask_data['subtask']['parameters']
                for param_name, param_value in base_subtask_params.items():
                    if param_value is None and param_name in curr_subtask_params:
                        base_subtask_params[param_name] = curr_subtask_params[param_name]

                base_subtask_actions.pop()

                merged_actions = base_subtask_actions + curr_subtask_actions
                base_subtask_data['actions'] = merged_actions

                original_subtasks_data.pop(original_pointer)

        return original_subtasks_data
    def delete_subtask(self, substask_name):
        self.page_manager.delete_subtask(substask_name)